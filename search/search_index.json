{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"overview/","title":"L'envers du d\u00e9cors","text":"<p>Mon objectif est donc de cr\u00e9er un NAS pour h\u00e9berger mes donn\u00e9es multim\u00e9dia (photos, vid\u00e9os, musique) et les services qui permettront de profiter de ces donn\u00e9es. L'objectif de ce serveur de stockage/NAS est d'\u00eatre \u00e9volutif, non ferm\u00e9 et bas\u00e9 sur des technologies 100 % open-source.</p> <p>En me documentant sur mon projet et comment j'allais arriver \u00e0 mes fins et construire ce NAS, je suis tomb\u00e9 sur beaucoup de sujets, tutos, etc... Et puis, un beau jour, j'ai ouvert un lien qui parlait du Perfect Media Server !</p> <p>Et la, bingo ! C'est exactement la documentation qu'il me fallait ! Vous aurez donc compris que mon projet est fortement inspir\u00e9 de ce qu'a r\u00e9alis\u00e9 Alex Kretzschmar (aka @IronicBadger).</p> <p>Toutes les technologies utilis\u00e9es dans le processus de cr\u00e9ation de son NAS me conviennent et c'est comme \u00e7a que je me suis retrouv\u00e9 \u00e0 \u00e9crire ma documentation pour ma propre machine.</p> <p>Note</p> <p>\u00c0 force de lire les nombreux tutos qui documentent le sujet et de voir les innombrables vid\u00e9os sous Youtube de mise en place de Homelab avec des partis pris technologiques forts, j'en suis arriv\u00e9 \u00e0 ne plus savoir comment allait \u00eatre structurer le NAS que je voulais mette en place :</p> <ul> <li>Quel syst\u00e8me d'exploitation install\u00e9 ?</li> <li>Qu'est-ce qui va \u00eatre virtualis\u00e9 ou non ?</li> <li>Quelles sont les briques logicielles qui vont fonctionner en baremetal (directement sur l'h\u00f4te et donc sur Proxmox et donc sur Debian Bookworm) ?</li> <li>Quelles sont les briques logicielles qui vont \u00eatre propuls\u00e9es via Docker ?</li> <li>D'ailleurs, comment installe-t-on Docker ? Sur une VM, un container LXC ?</li> </ul> <p>Ce sont toutes des questions l\u00e9gitimes sur lesquelles je me suis pench\u00e9 assez longtemps pour trouver la meilleure granularit\u00e9 du syst\u00e8me et suivant mes comp\u00e9tences (je ne suis pas sysadmin ou devops !) :</p> <ul> <li>Pour la mise \u00e0 jour syst\u00e8me,</li> <li>Pour l'upgrade mat\u00e9riel,</li> <li>Pour l'\u00e9volutivit\u00e9 des services propos\u00e9s.</li> </ul> <p>Vous retrouverez donc mes choix technologiques ci-dessous</p> <p>Il existes des solutions tout-en-un sur le march\u00e9 des logiciels libres ou non tels que OpenMediaVault, TrueNas Scale, Unraid qui s'int\u00e8grent tous pour cr\u00e9er ce genre de serveur. Bien qu'Unraid et OMV puissent r\u00e9pondre \u00e0 mes besoins de stockage en vrac, ils s'int\u00e8grent \u00e9galement avec certains compromis. \u00c0 d\u00e9faut, TrueNas Scale s'oriente surtout sur la gestion d'un pool de disques durs en ZFS, et on sait tous que ZFS n'est pas tr\u00e8s souple au niveau de l'\u00e9volutivit\u00e9 des disques.</p> <p>L'un des principaux moteurs de la cr\u00e9ation de ce NAS est la facilit\u00e9 de gestion de l'espace disque disponible. Je voulais \u00eatre en mesure d'\u00e9tendre ce dernier assez facilement sans mettre la main \u00e0 la poche en achetant mes disques durs directement au montage et pouvoir \u00e9taler ces achats au fur et \u00e0 mesure de la mont\u00e9e en charge du serveur.</p> <p>Je voulais, \u00e9galement, pouvoir \u00eatre en mesure d'ajouter un seul disque et de l'ajouter \u00e0 la capacit\u00e9 du pool de stockage tout en conservant une certaine redondance avec un minimum de configuration et de temps d'arr\u00eat.</p> <ul> <li> <p> Mat\u00e9riel &amp; m\u00e9thodologie</p> <ul> <li>Voici la liste du mat\u00e9riel que j'ai acquis pour ce projet.</li> <li>La m\u00e9thodologie qui va nous permettre de construire ce NAS.</li> </ul> <p> En savoir plus</p> </li> <li> <p> Guide d'installation</p> <p>Guides pour l'installation de Proxmox Virtual Environment et de l'ensemble des outils du serveur.</p> <p> D\u00e9buter l'installation</p> </li> <li> <p> Post-installation</p> <p>Le vrai coeur du syst\u00e8me est ici !</p> <p> Lire la documentation</p> </li> <li> <p> Services</p> <p>Cr\u00e9ons l'ensemble de nos services !</p> <p> Explorez l'ensemble des services</p> </li> </ul>"},{"location":"installation/proxmox/","title":"INSTALLATION - Proxmox","text":""},{"location":"installation/proxmox/#basique-avec-options-lvm","title":"Basique avec options LVM","text":""},{"location":"installation/proxmox/#objectif","title":"Objectif","text":"<ul> <li>Installer un serveur Proxmox,</li> <li>Par d\u00e9faut, l'installation de Proxmox cr\u00e9e un groupe de volumes (VG) appel\u00e9 <code>pve</code> et des volumes logiques (LV) associ\u00e9s appel\u00e9s <code>root</code>, <code>data</code> et <code>swap</code>. Dans notre cas, nous allons faire une installation sans volume de donn\u00e9es <code>local-lvm</code> de type <code>LVM-Thin</code>. Pour contr\u00f4ler la taille de ces volumes, il est possible de modifier les options avanc\u00e9es via cette bo\u00eete de dialogue : </li> </ul> Options avanc\u00e9es LVM <ul> <li>Le but est de configurer ce volume logique <code>/dev/pve-data</code> en post installation afin de pouvoir avoir la main totale sur celui-ci,</li> <li>Nous allons aussi d\u00e9sactiver le stockage par d\u00e9faut <code>local (/var/lib/vz)</code> qui se trouve sur notre volume logique <code>/dev/pve-root</code>.</li> </ul> <p>Pourquoi ?</p> <p>Ce stockage est un stockage de type <code>Directory</code> dans le r\u00e9pertoire <code>/var/lib/vz</code> qui se trouve sur le volume logique <code>pve-root</code> de notre serveur, c'est-\u00e0-dire sur la partition syst\u00e8me de notre serveur. Avec la mont\u00e9e en charge de ce dernier, cet espace de stockage va se remplir d'images ISO, de mod\u00e8les de container LXC ou encore d'image disque de nos VMs/CTs et occuper tout l'espace disque d\u00e9di\u00e9 au syst\u00e8me d'exploitation. Ce que l'on ne veut pas qu'il arrive !</p>"},{"location":"installation/proxmox/#installation","title":"Installation","text":"<ul> <li>Booter sur Ventoy en ayant pr\u00e9alablement t\u00e9l\u00e9charger et copier l'image ISO de Proxmox Virtual Environment,</li> <li>Installation de Proxmox :</li> </ul> Installation de Proxmox en mode graphique S\u00e9quence de boot Validez la license Choisir le disque cible pour l'installation <ul> <li>Suivant la taille de notre disque dur d'installation, configurer l'installation avec ses valeurs d'options avanc\u00e9es de configuration LVM :<ul> <li><code>hdsize = 128GO</code>,</li> <li><code>swapsize = 8GO</code>,</li> <li><code>maxroot = 64GO</code>,</li> <li><code>maxvz = 0GO</code> Ici, cela permet de sp\u00e9cifier \u00e0 l'installateur de ne pas cr\u00e9er de stockage LVM,</li> <li><code>minfree = 16GO</code></li> </ul> </li> </ul> Options avanc\u00e9es de configuration LVM Configuration du r\u00e9seau Configuration de la zone de temps R\u00e9capitulatif de l'installation et on valide l'installation Installation en cours... Installation en cours... Installation en cours... Installation termin\u00e9e https://192.168.10.5:8006/"},{"location":"installation/proxmox/#en-mirroir-avec-zfs-raid1","title":"En mirroir avec ZFS &amp; RAID1","text":""},{"location":"installation/proxmox/#objectif_1","title":"Objectif","text":"<p>Coming soon</p>"},{"location":"installation/proxmox/#installation_1","title":"Installation","text":"<ul> <li>Booter sur Ventoy en ayant pr\u00e9alablement t\u00e9l\u00e9charger et copier l'image ISO de Proxmox Virtual Environment,</li> <li>Installation de Proxmox :</li> </ul> Installation de Proxmox en mode graphique S\u00e9quence de boot Validez la license Cliquez sur Options pour param\u00e9trer l'installation en ZFS Mirroir RAID1 Dans l'onglet Disk Setup, mapper les 2 disques qui vont nous servir pour l'installation de Proxmox. Ici, /dev/sda et /dev/sdb Dans l'onglet Advanced Options, j'ai juste modifi\u00e9 l'option de compression compress en lz4 Configuration de la zone de temps Mot de passe et contact Configuration du r\u00e9seau proxmox-install-summary Installation en cours... Installation en cours... Installation achev\u00e9e Interface d'administration"},{"location":"post-install/","title":"POST-INSTALLATION - Proxmox","text":""},{"location":"post-install/#administration-de-lhyperviseur","title":"Administration de l'hyperviseur","text":"<ul> <li> <p> Configuration Proxmox</p> <ul> <li>D\u00e9sactiver les d\u00e9p\u00f4ts <code>pve-enterprise</code> et <code>ceph</code></li> <li>Activer le d\u00e9p\u00f4t <code>pve-no-subscription</code></li> <li>D\u00e9sactiver le stockage par d\u00e9faut <code>local</code></li> <li>Partitionner le reste de l'espace disque restant afin de cr\u00e9er le stockage <code>LVM-Thin</code></li> <li>XXXXX</li> </ul> </li> <li> <p> Syst\u00e8me</p> <ul> <li>Installer les paquets indispensables \u00e0 la vie du serveur</li> <li>Configuration <code>SSH</code></li> <li>XXXXX</li> </ul> </li> <li> <p> Donn\u00e9es et stockage</p> <ul> <li>Installer et configurer <code>mergerFS</code></li> <li>Installer et configurer <code>SnapRAID</code></li> <li>XXXXX</li> <li>XXXXX</li> </ul> </li> </ul>"},{"location":"post-install/data-storage/mergerfs/","title":"mergerFS","text":"<p>Mergerfs est l'outil magique de notre NAS ! Voici la proc\u00e9dure d'installation.</p> <p>L'installation dans Ubuntu ou Debian peut \u00eatre effectu\u00e9e \u00e0 l'aide d'<code>apt</code> mais la version dans les d\u00e9p\u00f4ts est g\u00e9n\u00e9ralement toujours un peu \u00e0 la tra\u00eene. </p> <p>Pour installer <code>mergerFS</code>, on va pr\u00e9f\u00e9rer utiliser le fichier *.deb que l'on peut t\u00e9l\u00e9charger sur le d\u00e9p\u00f4t https://github.com/trapexit/mergerfs/releases</p>"},{"location":"post-install/data-storage/mergerfs/#installation-sous-debian-bookworm-12","title":"Installation sous debian Bookworm (12)","text":"<pre><code>root@homelab:~# wget https://github.com/trapexit/mergerfs/releases/download/2.40.2/mergerfs_2.40.2.debian-bookworm_amd64.deb\nroot@homelab:~# dpkg -i mergerfs_2.40.2.debian-bookworm_amd64.deb\n</code></pre> <p>On v\u00e9rifie que l'installation est effective :</p> <pre><code>root@homelab:~# mergerfs --version\nmergerfs v2.40.2\n\nhttps://github.com/trapexit/mergerfs\nhttps://github.com/trapexit/support\n\nISC License (ISC)\n\nCopyright 2023, Antonio SJ Musumeci &lt;trapexit@spawn.link&gt;\n\nPermission to use, copy, modify, and/or distribute this software for\nany purpose with or without fee is hereby granted, provided that the\nabove copyright notice and this permission notice appear in all\ncopies.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL\nWARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE\nAUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL\nDAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR\nPROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER\nTORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\nPERFORMANCE OF THIS SOFTWARE.\n</code></pre>"},{"location":"post-install/data-storage/mergerfs/#configuration-des-disques-dur","title":"Configuration des disques dur","text":"<p>La section suivante d\u00e9taille les \u00e9tapes pour identifier, monter et partitionner les disques durs de votre syst\u00e8me.</p>"},{"location":"post-install/data-storage/mergerfs/#monter-ses-disques-manuellement","title":"Monter ses disques manuellement","text":"<p>Afin d'utiliser les disques durs pr\u00e9sents sur notre NAS, notre syst\u00e8me d'exploitation doit les monter. Le montage signifie que nous fournissons au syst\u00e8me d'exploitation des instructions sur la fa\u00e7on de lire ou d'\u00e9crire des donn\u00e9es sur un lecteur sp\u00e9cifique. Afin d'\u00eatre le plus compatible avec <code>mergerFS</code>, il est conseill\u00e9 de configurer les disques \u00e0 utiliser avec notre NAS avec une unique partition et \u00e0 la formater avec un seul syst\u00e8me de fichiers qui s'\u00e9tend sur l'int\u00e9gralit\u00e9 du disque, souvent <code>ext4</code> ou <code>xfs</code>, puis \u00e0 les monter sur le syt\u00e8me.</p> <p>Il y a de multiples syst\u00e8mes de fichiers disponibles sous Linux et il n\u2019y a pas de bon ou de mauvais choix. Cependant, on recommande l'<code>ext4</code> ou <code>xfs</code> pour rester dans des choses simples.</p> <p>Info</p> <p>N'oubliez pas qu'avec mergerFS, on peut m\u00e9langer et faire correspondre en toute s\u00e9curit\u00e9 les syst\u00e8mes de fichiers et les tailles de lecteur, ce qui fait partie de sa v\u00e9ritable magie. </p> <p>Cela signifie que vous n'avez pas \u00e0 trop vous soucier de choisir exactement le bon syst\u00e8me de fichiers d\u00e8s le d\u00e9part, car vous n'\u00eates pas enferm\u00e9.</p>"},{"location":"post-install/data-storage/mergerfs/#identification-des-disques-durs","title":"Identification des disques durs","text":"<p>R\u00e9pertoriez tous les lecteurs d'un syst\u00e8me avec :</p> <p><pre><code>root@homelab:~# ls -l /dev/disk/by-id\n\nlrwxrwxrwx 1 root root  9 Mar 26 14:52 ata-VBOX_HARDDISK_VB2ff4aa6e-3b5752ba -&gt; ../../sdd\nlrwxrwxrwx 1 root root  9 Mar 26 14:52 ata-VBOX_HARDDISK_VB41f1fa4d-a2c11c14 -&gt; ../../sdf\nlrwxrwxrwx 1 root root  9 Mar 26 14:52 ata-VBOX_HARDDISK_VB4d776a0a-b24c3eb0 -&gt; ../../sda\nlrwxrwxrwx 1 root root 10 Mar 26 14:52 ata-VBOX_HARDDISK_VB4d776a0a-b24c3eb0-part1 -&gt; ../../sda1\nlrwxrwxrwx 1 root root 10 Mar 26 14:52 ata-VBOX_HARDDISK_VB4d776a0a-b24c3eb0-part2 -&gt; ../../sda2\nlrwxrwxrwx 1 root root 10 Mar 26 14:52 ata-VBOX_HARDDISK_VB4d776a0a-b24c3eb0-part3 -&gt; ../../sda3\nlrwxrwxrwx 1 root root  9 Mar 26 14:52 ata-VBOX_HARDDISK_VB4fd111ed-7ccb2978 -&gt; ../../sdb\nlrwxrwxrwx 1 root root 10 Mar 26 14:52 ata-VBOX_HARDDISK_VB4fd111ed-7ccb2978-part1 -&gt; ../../sdb1\nlrwxrwxrwx 1 root root 10 Mar 26 14:52 ata-VBOX_HARDDISK_VB4fd111ed-7ccb2978-part2 -&gt; ../../sdb2\nlrwxrwxrwx 1 root root 10 Mar 26 14:52 ata-VBOX_HARDDISK_VB4fd111ed-7ccb2978-part3 -&gt; ../../sdb3\nlrwxrwxrwx 1 root root  9 Mar 26 14:52 ata-VBOX_HARDDISK_VBb598f427-91b62771 -&gt; ../../sdc\nlrwxrwxrwx 1 root root  9 Mar 26 14:52 ata-VBOX_HARDDISK_VBbc16d229-98501233 -&gt; ../../sde\n</code></pre> Ou avec : <pre><code>root@homelab:~# ls -l /dev/disk/by-uuid\n\ntotal 0\nlrwxrwxrwx 1 root root  9 Mar 26 14:52 01418e86-d606-4d40-acf4-79af5045172c -&gt; ../../sdc\nlrwxrwxrwx 1 root root 10 Mar 26 14:52 4F35-0F4B -&gt; ../../sda2\nlrwxrwxrwx 1 root root 10 Mar 26 14:52 4F3A-0665 -&gt; ../../sdb2\nlrwxrwxrwx 1 root root 10 Mar 26 14:52 9126907211302610478 -&gt; ../../sda3\n</code></pre></p> <p>Ou encore : <pre><code>root@homelab:~# fdisk -l\nDisk /dev/sda: 1 TiB, 1099511627776 bytes, 2147483648 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: 30CEC8C0-5E64-4538-BCB6-14419B0A845D\n\nDevice       Start        End    Sectors  Size Type\n/dev/sda1       34       2047       2014 1007K BIOS boot\n/dev/sda2     2048    2099199    2097152    1G EFI System\n/dev/sda3  2099200 2147483614 2145384415 1023G Solaris /usr &amp; Apple ZFS\n\nroot@homelab:~# fdisk -l\nDisk /dev/sda: 1 TiB, 1099511627776 bytes, 2147483648 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: 30CEC8C0-5E64-4538-BCB6-14419B0A845D\n\nDevice       Start        End    Sectors  Size Type\n/dev/sda1       34       2047       2014 1007K BIOS boot\n/dev/sda2     2048    2099199    2097152    1G EFI System\n/dev/sda3  2099200 2147483614 2145384415 1023G Solaris /usr &amp; Apple ZFS\n\n\nDisk /dev/sdb: 1 TiB, 1099511627776 bytes, 2147483648 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: 1938A24D-F234-4DAE-958D-964B26179408\n\nDevice       Start        End    Sectors  Size Type\n/dev/sdb1       34       2047       2014 1007K BIOS boot\n/dev/sdb2     2048    2099199    2097152    1G EFI System\n/dev/sdb3  2099200 2147483614 2145384415 1023G Solaris /usr &amp; Apple ZFS\n\n\nDisk /dev/sdc: 128 GiB, 137438953472 bytes, 268435456 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/sdd: 2 TiB, 2199022206976 bytes, 4294965248 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/sde: 2 TiB, 2199022206976 bytes, 4294965248 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\n\nDisk /dev/sdf: 2 TiB, 2199022206976 bytes, 4294965248 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n</code></pre></p> <p>Cette liste va nous permettre d'identifier les disques et de mapper les lecteurs \u00e9ph\u00e9m\u00e8res tels que <code>/dev/sda</code> et <code>ata-HGST_HDN728080ALE604_R6GPPDTY</code> qui est l'ID. du disque dur. </p> <p>Inversement, pour l'identification du lecteur \u00e9ph\u00e9m\u00e8re, on peut le faire en utilisant cette commande : <pre><code>root@homelab:~# ls -l /dev/disk/by-id/ata-HGST_HDN728080ALE604_R6GPPDTY\nlrwxrwxrwx 1 root root 9 Sep  9 23:08 /dev/disk/by-id/ata-HGST_HDN728080ALE604_R6GPPDTY -&gt; ../../sda\n</code></pre></p> <p>Par cons\u00e9quent, nous pouvons v\u00e9rifier que <code>/dev/sda</code> est mapp\u00e9 sur ce lecteur physique.</p> <p>Warning</p> <p>N'utilisez jamais <code>/dev/sdX</code> comme solution \u00e0 long terme pour l'identification du lecteur, car ces identifiants peuvent changer et changent sans avertissement en raison d'autres modifications mat\u00e9rielles, mises \u00e0 niveau du noyau, etc...</p> <p>L'identifiant <code>/dev/disk/by-id</code> est li\u00e9 \u00e0 cet \u00e9l\u00e9ment sp\u00e9cifique du mat\u00e9riel, par mod\u00e8le de lecteur et num\u00e9ro de s\u00e9rie et ne changera donc jamais.</p>"},{"location":"post-install/data-storage/mergerfs/#partitionnement","title":"Partitionnement","text":"<p>Avant de cr\u00e9er une partition sur un disque dur fraichement sorti de son emballage, assurez-vous de l'avoir \u00ab grav\u00e9 \u00bb comme explicit\u00e9 ici : Rituel de gravure de disque dur neuf.</p> <p>Warning</p> <p>ATTENTION - Nous sommes sur le point d'effectuer des \u00e9tapes destructrices sur la table de partition du lecteur. S'il y a des donn\u00e9es existantes sur ce disque, elles seront effac\u00e9es. Assurez-vous d'\u00eatre prudent et r\u00e9fl\u00e9chi auquel cas vous allez perdre vos donn\u00e9es !</p> <p>Les \u00e9tapes suivantes n\u00e9cessiteront un acc\u00e8s root. En utilisant notre exemple de lecteur de la section pr\u00e9c\u00e9dente, nous utiliserons l'utilitaire <code>cfdisk</code> et ou <code>sgdisk</code> pour cr\u00e9er une nouvelle partition et un nouveau syst\u00e8me de fichiers.</p> <p>Note</p> <p>Faisons l'exercice pour le disque qui nous servira de disque de parit\u00e9 pour Snapraid. Le processus sera le m\u00eame p\u00f4ur les disques de donn\u00e9es.</p> <p>Si le disque n'est pas vide et que vous souhaitez repartir sur un disque nu.</p> <p>Suppression des tables de partition (le volume appara\u00eet comme sans table de partition) : <pre><code>root@homelab:~# sgdisk /dev/sdd -Z\n</code></pre> Cr\u00e9ation d'une table de partition gpt et v\u00e9rification du disque :</p> Partionnement d'un disque"},{"location":"post-install/data-storage/mergerfs/#creation-du-systeme-de-fichiers","title":"Cr\u00e9ation du syst\u00e8me de fichiers","text":"<p>Cr\u00e9ez un syst\u00e8me de fichiers ext4 (remplacez X par votre lettre de lecteur) avec une \u00e9tiquette : <pre><code>root@homelab:~# mkfs.ext4 -L PARITY /dev/sdd1\nDisk /dev/sdd: 2 TiB, 2199022206976 bytes, 4294965248 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: 80560CA3-03D0-134F-9107-6B1DE289A724\n\nDevice     Start        End    Sectors Size Type\n/dev/sdd1   2048 4294963199 4294961152   2T Linux filesystem\nroot@homelab:~# mkfs.ext4 /dev/sdd1\nmke2fs 1.47.0 (5-Feb-2023)\nCreating filesystem with 536870144 4k blocks and 134217728 inodes\nFilesystem UUID: 810c4257-aa5c-447f-b839-545e37ad7bcf\nSuperblock backups stored on blocks: \n        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, \n        4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968, \n        102400000, 214990848, 512000000\n\nAllocating group tables: done                            \nWriting inode tables: done                            \nCreating journal (262144 blocks): done\nWriting superblocks and filesystem accounting information: done\n</code></pre> Votre nouveau disque est maintenant format\u00e9 et pr\u00eat \u00e0 stocker des donn\u00e9es.</p>"},{"location":"post-install/data-storage/mergerfs/#points-de-montage","title":"Points de montage","text":"<p>Les points de montage sont l'endroit o\u00f9 le syst\u00e8me d'exploitation monte une partition de disque sp\u00e9cifique. Par exemple, vous pouvez avoir plusieurs partitions sur le m\u00eame disque mont\u00e9es \u00e0 diff\u00e9rents endroits pour des raisons de redondance ou de performances. Pour nos besoins ici, nous garderons les choses simples en montant chaque partition de disque de donn\u00e9es une par une.</p> <p>En supposant que le test pr\u00e9c\u00e9dent s'est bien pass\u00e9, il est temps de proposer un sch\u00e9ma de d\u00e9nomination des points de montage. Je vous recommande /mnt/diskN car il simplifie l'entr\u00e9e fstab pour les fusions gr\u00e2ce \u00e0 la prise en charge des caract\u00e8res g\u00e9n\u00e9riques Linux.</p> <p>Note</p> <p>N'oubliez pas de r\u00e9p\u00e9ter le partitionnement des disques de donn\u00e9es au pr\u00e9ablable via <code>cfdisk</code> comme vu pr\u00e9c\u00e9demment sur le disque de parit\u00e9 /dev/sdd.</p> <p>Warning</p> <p>ATTENTION - Nous sommes sur le point d'effectuer des \u00e9tapes destructrices sur la table de partition du lecteur. S'il y a des donn\u00e9es existantes sur ce disque, elles seront effac\u00e9es. Assurez-vous d'\u00eatre prudent et r\u00e9fl\u00e9chi auquel cas vous allez perdre vos donn\u00e9es !</p> <p>Par exemple: <pre><code>root@homelab:~# mkdir /mnt/parity\nroot@homelab:~# mount /dev/sdd1 /mnt/parity\n# ON PEUT AUSSI MONTER LA PARTITION VIA SON ID\n# ls -l /dev/disk/by-id/\nroot@homelab:~# mount /dev/disk/by-id/ata-VBOX_HARDDISK_VB2ff4aa6e-3b5752ba-part1 /mnt/parity\n# ON PEUT ENCORE MONTER LA PARTITION VIA SON UUID\n# ls -l /dev/disk/by-uuid/\nroot@homelab:~# mount /dev/disk/by-uuid/255626b6-4990-4a78-85f2-00a84393719c /mnt/parity\n\nroot@homelab:~# mkfs.ext4 -L DATA01 /dev/sde1\nroot@homelab:~# mkfs.ext4 -L DATA02 /dev/sdf1\nroot@homelab:~# mkdir /mnt/data0{1,2}\nroot@homelab:~# mount /dev/sde1 /mnt/data01\nroot@homelab:~# mount /dev/sdf1 /mnt/data02\n\nroot@homelab:~# mkdir /mnt/storage\n</code></pre></p>"},{"location":"post-install/data-storage/mergerfs/#entrees-fstab","title":"Entr\u00e9es FSTAB","text":"<p>Ensuite, nous devons cr\u00e9er une entr\u00e9e dans <code>/etc/fstab</code>. Ce fichier indique \u00e0 votre syst\u00e8me d'exploitation comment, o\u00f9 et quels disques monter.  Cela semble un peu complexe mais une entr\u00e9e fstab est en fait assez simple et se d\u00e9compose en :</p> <ul> <li><code>device</code> &gt; <code>mountpoint</code> &gt; <code>filesystem</code> &gt; <code>options</code> &gt; <code>dump</code> &gt;<code>fsck</code> - documentation fstab.</li> </ul>"},{"location":"post-install/data-storage/mergerfs/#via-lid-des-disques-durs","title":"Via l'ID des disques durs","text":"<pre><code>root@homelab:~# vi /etc/fstab\n\n# MERGERFS\n/dev/disk/by-id/ata-VBOX_HARDDISK_VB2ff4aa6e-3b5752ba-part1 /mnt/parity ext4 defaults 0 0\n/dev/disk/by-id/ata-VBOX_HARDDISK_VB41f1fa4d-a2c11c14-part1 /mnt/data01 ext4 defaults 0 0\n/dev/disk/by-id/ata-VBOX_HARDDISK_VBbc16d229-98501233-part1 /mnt/data02 ext4 defaults 0 0\n\n# Notez que mergerfs ne monte pas le lecteur de parit\u00e9, il monte uniquement /mnt/data0*.\n# Mergerfs n'a rien \u00e0 voir avec la parit\u00e9, pour cela, nous utilisons SnapRAID.\n/mnt/data0* /mnt/storage fuse.mergerfs defaults,nonempty,cache.files=off,category.create=epmfs,moveonenospc=true,dropcacheonclose=true,minfreespace=5G,fsname=mergerfs 0 0\n</code></pre>"},{"location":"post-install/data-storage/mergerfs/#via-luuid-des-disques-durs","title":"Via l'UUID des disques durs","text":"<pre><code>root@homelab:~# vi /etc/fstab\n\n# MERGERFS\nUUID=\"255626b6-4990-4a78-85f2-00a84393719c\" /mnt/parity ext4 defaults 0 0\nUUID=\"0ff04694-f4ca-4442-8d58-7ec2b23ad3a8\" /mnt/data01 ext4 defaults 0 0\nUUID=\"32b0ee6b-6cc4-44ce-8ed1-866138365a50\" /mnt/data02 ext4 defaults 0 0\n\n# Notez que mergerfs ne monte pas le lecteur de parit\u00e9, il monte uniquement /mnt/data0*.\n# Mergerfs n'a rien \u00e0 voir avec la parit\u00e9, pour cela, nous utilisons SnapRAID.\n/mnt/data0* /mnt/storage fuse.mergerfs defaults,nonempty,cache.files=off,category.create=epmfs,moveonenospc=true,dropcacheonclose=true,minfreespace=5G,fsname=mergerfs 0 0\n</code></pre> <p>Visualisation des points de montage : <pre><code>root@homelab:~# df -h\nFilesystem        Size  Used Avail Use% Mounted on\nudev              3.9G     0  3.9G   0% /dev\ntmpfs             794M  836K  793M   1% /run\nrpool/ROOT/pve-1  985G  1.8G  983G   1% /\ntmpfs             3.9G   43M  3.9G   2% /dev/shm\ntmpfs             5.0M     0  5.0M   0% /run/lock\nmergerfs          4.0T   56K  3.8T   1% /mnt/storage\n/dev/sdc          125G   40K  119G   1% /mnt/iso\n/dev/sdf1         2.0T   28K  1.9T   1% /mnt/data01\n/dev/sdd1         2.0T   28K  1.9T   1% /mnt/parity\n/dev/sde1         2.0T   28K  1.9T   1% /mnt/data02\nrpool/pgdata      983G  128K  983G   1% /var/lib/postgresql\nrpool/var-lib-vz  983G  128K  983G   1% /var/lib/vz\nrpool             983G  128K  983G   1% /rpool\nrpool/ROOT        983G  128K  983G   1% /rpool/ROOT\nrpool/data        983G  128K  983G   1% /rpool/data\n/dev/fuse         128M   16K  128M   1% /etc/pve\ntmpfs             794M     0  794M   0% /run/user/0\n</code></pre></p>"},{"location":"post-install/data-storage/mergerfs/#options-de-montage-de-mergerfs","title":"Options de montage de mergerfs","text":"<p>La documentation : https://github.com/trapexit/mergerfs?tab=readme-ov-file#options et le rappel de la politique de stockage utilis\u00e9e</p> <ul> <li>minfreespace = SIZE :<ul> <li>valeur d'espace minimale utilis\u00e9e pour les strat\u00e9gies de cr\u00e9ation. Peut \u00eatre remplac\u00e9 par une option sp\u00e9cifique \u00e0 la branche. Comprend \u00ab\u00a0K\u00a0\u00bb, \u00ab\u00a0M\u00a0\u00bb et \u00ab\u00a0G\u00a0\u00bb comme repr\u00e9sentant respectivement le kilo-octet, le m\u00e9gaoctet et le gigaoctet. (par d\u00e9faut : 4G)</li> </ul> </li> <li>moveonenospc = BOOL|POLICY : <ul> <li>Lorsqu'elle est activ\u00e9e si une \u00e9criture \u00e9choue avec ENOSPC (aucun espace disponible sur l'appareil) ou EDQUOT (quota de disque d\u00e9pass\u00e9), la strat\u00e9gie s\u00e9lectionn\u00e9e s'ex\u00e9cutera pour trouver un nouvel emplacement pour le fichier. Une tentative de d\u00e9placement du fichier vers cette branche se produira (en gardant toutes les m\u00e9tadonn\u00e9es possibles) et en cas de succ\u00e8s, l'original sera dissoci\u00e9 et l'\u00e9criture sera r\u00e9essay\u00e9e. (par d\u00e9faut\u00a0: faux, vrai = mfs)</li> </ul> </li> <li>dropcacheonclose = BOOL :<ul> <li>Lorsqu'il est demand\u00e9 de fermer un fichier, appelez d'abord posix_fadvise pour indiquer au noyau que nous n'avons plus besoin des donn\u00e9es et qu'il peut supprimer son cache. Recommand\u00e9 lorsque cache.files=partial|full|auto-full|per-process pour limiter la double mise en cache. (par d\u00e9faut : faux)</li> </ul> </li> <li>category.action = POLICY :<ul> <li>D\u00e9finit la politique de toutes les fonctions FUSE dans la cat\u00e9gorie d'action. (par d\u00e9faut : epall)</li> </ul> </li> <li>category.create = POLICY :<ul> <li>D\u00e9finit la politique de toutes les fonctions FUSE dans la cat\u00e9gorie de cr\u00e9ation. (par d\u00e9faut : epmfs)</li> </ul> </li> <li>category.search = POLICY :<ul> <li>D\u00e9finit la politique de toutes les fonctions FUSE dans la cat\u00e9gorie de recherche. (par d\u00e9faut : ff)</li> </ul> </li> <li>cache.files = libfuse|off|partial|full|auto-full|per-process :<ul> <li>Mode de mise en cache des pages de fichiers (par d\u00e9faut : libfuse)</li> </ul> </li> <li>fsname = STR :<ul> <li>D\u00e9finit le nom du syst\u00e8me de fichiers tel qu'il appara\u00eet dans mount, df, etc. La valeur par d\u00e9faut est une liste des chemins sources concat\u00e9n\u00e9s avec le pr\u00e9fixe commun le plus long supprim\u00e9.</li> </ul> </li> </ul> <p>Afin de recharger les nouvelles entr\u00e9es <code>fstab</code> que nous avons cr\u00e9\u00e9es et de les v\u00e9rifier avant de red\u00e9marrer, montons-les <pre><code>root@homelab:~# mount -a\n</code></pre></p> <p>V\u00e9rifiez ensuite les points de montage avec <code>df -h</code> ou enocre <code>duf</code> : <pre><code>root@homelab:~# \n</code></pre></p>"},{"location":"post-install/data-storage/mergerfs/#exemple-darborescence-des-fichiers","title":"Exemple d'arborescence des fichiers","text":"<pre><code>root@homelab:/# tree /mnt/data01\n\n/mnt/data01/\n\u251c\u2500\u2500 lost+found\n\u2514\u2500\u2500 media\n    \u251c\u2500\u2500 musics\n    \u251c\u2500\u2500 photos\n    \u2514\u2500\u2500 videos\n\nroot@homelab:/# tree /mnt/data02\n/mnt/data02\n\u251c\u2500\u2500 backups\n\u2502   \u2514\u2500\u2500 proxmox\n\u251c\u2500\u2500 docker\n\u2502   \u2514\u2500\u2500 appdata\n\u2514\u2500\u2500 lost+found\n\nroot@homelab:/# tree /mnt/storage\n/mnt/storage/\n\u251c\u2500\u2500 backups\n\u2502   \u2514\u2500\u2500 proxmox\n\u251c\u2500\u2500 docker\n\u2502   \u2514\u2500\u2500 appdata\n\u251c\u2500\u2500 lost+found\n\u2514\u2500\u2500 media\n    \u251c\u2500\u2500 musics\n    \u251c\u2500\u2500 photos\n    \u2514\u2500\u2500 videos\n</code></pre>"},{"location":"post-install/data-storage/nfs-samba/","title":"NFS/Samba","text":""},{"location":"post-install/data-storage/nfs-samba/#configurer-un-partage-samba","title":"Configurer un partage Samba","text":""},{"location":"post-install/data-storage/nfs-samba/#installation-de-samba","title":"Installation de Samba","text":"<pre><code>sudo apt install samba smbclient cifs-utils\n</code></pre>"},{"location":"post-install/data-storage/nfs-samba/#definir-les-parametres-globaux-de-samba","title":"D\u00e9finir les param\u00e8tres globaux de Samba","text":"<p>Editer le fichier /etc/samba/smb.conf :</p> <pre><code>[public]\n    comment = Public Folder \n    path = /public \n    writable = yes \n    guest ok = yes \n    guest only = yes \n    force create mode = 775 \n    orce directory mode = 775 \n\n[private]\n    comment = Private Folder\n    path = /private\n    writable = yes\n    guest ok = no\n    valid users = @smbshare\n    force create mode = 770\n    force directory mode = 770\n    inherit permissions = yes\n\n[NUC-Home]\n   comment = NUC - Home\n   path = /home/docker\n   guest ok = no\n   read only = no\n   browseable = yes\n   writeable = yes\n   valid users = docker\n</code></pre>"},{"location":"post-install/data-storage/nfs-samba/#creer-un-utilisateur-et-un-groupe-samba","title":"Cr\u00e9er un utilisateur et un groupe Samba","text":"<p>Nous avons besoin du groupe d'utilisateurs de partage Samba pour acc\u00e9der au partage priv\u00e9 comme sp\u00e9cifi\u00e9 dans la configuration ci-dessus. Nous allons donc cr\u00e9er le groupe comme ci-dessous.</p> <pre><code>sudo groupadd smbshare\n</code></pre> <p>Ajoutez les autorisations n\u00e9cessaires pour le partage priv\u00e9.</p> <pre><code>sudo chgrp -R smbshare /private/\nsudo chgrp -R smbshare /public\n</code></pre> <p>D\u00e9finissez les bonnes autorisations de r\u00e9pertoire. <pre><code>sudo chmod 2770 /private/\nsudo chmod 2775 /public\n</code></pre></p> <p>Dans la commande ci-dessus, la valeur 2 au d\u00e9but correspond au stickybit. Cela permet aux fichiers nouvellement cr\u00e9\u00e9s d'h\u00e9riter du groupe parent.</p> <p>Ensuite, cr\u00e9ez un utilisateur local sans connexion pour acc\u00e9der au partage priv\u00e9 : <pre><code>sudo useradd -M -s /sbin/nologin sambauser\n</code></pre></p> <p>Ajoutez l'utilisateur au groupe de partage Samba cr\u00e9\u00e9 ci-dessus : <pre><code>sudo usermod -aG smbshare sambauser\n</code></pre></p> <p>Cr\u00e9ez maintenant un mot de passe SMB pour l'utilisateur : <pre><code>sudo smbpasswd -a sambauser```\n\nActivez le compte cr\u00e9\u00e9 :\n``` bash\nsudo smbpasswd -e sambauser\n</code></pre></p>"},{"location":"post-install/data-storage/nfs-samba/#verifiez-la-configuration-de-samba","title":"V\u00e9rifiez la configuration de Samba","text":"<p>Une fois les modifications apport\u00e9es au fichier de configuration, il est recommand\u00e9 de le tester \u00e0 l'aide de la commande ci-dessous\u00a0: <pre><code>sudo testparm\n</code></pre></p> <p>Si vous n'avez pas de message d'erreur, on red\u00e9marre le service : <pre><code>sudo systemctl restart nmbd\n</code></pre></p>"},{"location":"post-install/data-storage/nfs-samba/#acceder-aux-partages-depuis-un-client","title":"Acc\u00e9der aux partages depuis un client","text":"<p>Ce guide montre comment acc\u00e9der aux fichiers partag\u00e9s \u00e0 l'aide des syst\u00e8mes Windows et Linux. Tout d\u2019abord, essayez d\u2019acc\u00e9der au partage depuis votre ordinateur local.</p> <pre><code>smbclient '\\\\localhost\\private' -U sambauser\n</code></pre>"},{"location":"post-install/data-storage/nfs-samba/#configurer-le-partage-de-fichier-sur-freebox-os","title":"Configurer le partage de fichier sur Freebox OS","text":"<ul> <li>Pr\u00e9requis :<ul> <li>Sur la console d'administration du routeur Freebox : http://mafreebox.freebox.fr/<ul> <li>Dans la rubrique Param\u00e8tres de la Freebox, puis\u00a0Partage de fichiers\u00a0cliquez sur\u00a0Partages Windows :  </li> </ul> </li> </ul> </li> </ul> <p>Il faudra renseigner le nom d\u2019utilisateur et mot de passe pour acc\u00e9der au partage et son activation</p> <ul> <li>Sur le client Debian :</li> </ul> <pre><code>sudo apt-get install cifs-utils\n\nsudo mkdir /media/freebox/\n\nsudo touch /home/$USER/.smbcredentials\n</code></pre> <p>Edition du fichier .smbcredentials* : <pre><code>sudo nano /home/$USER/.smbcredentials\n</code></pre></p> <p>Dans le fichier, ajoutez les lignes suivantes (remplacez les XXXX par votre login et mot de passe) : <pre><code>username=freebox\npassword=mypassword\ndomain=WORKGROUP\n</code></pre></p> <p>Donnez les droits ad\u00e9quats au fichier\u00a0.smbcredentials\u00a0: <pre><code>sudo chown -R $USER:root /home/$USER/.smbcredentials\nsudo chmod -R 775 /home/$USER/.smbcredentials\n</code></pre></p> <p>Montage \u00e0 la vol\u00e9e : <pre><code>sudo mount -t cifs //mafreebox.freebox.fr/Disque\\ dur/Vid\u00e9os /home/docker/media/videos/freebox -o rw,uid=1000,gid=1000,credentials=/home/docker/.smbcredentials,iocharset=utf8,file_mode=0777,dir_mode=0777\n</code></pre></p> <p>Afin d\u2019avoir un comportement semblable \u00e0 Windows, c\u2019est-\u00e0-dire, retrouver le partage dans l\u2019explorateur de fichier et cela, m\u00eame apr\u00e8s un red\u00e9marrage, il faut monter le partage dans le fichier fstab afin que celui-ci soit bien remonter apr\u00e8s red\u00e9marrage de la machine.</p> <p>Avant toute modifications, nous allons faire une sauvegarde de l\u2019ancienne configuration : <pre><code>sudo cp /etc/fstab /etc/fstab.old\n</code></pre></p> <p>\u00c0 pr\u00e9sent, on va ajouter l\u2019acc\u00e8s au partage Freebox dans fstab : <pre><code># MONTAGE DU PARTAGE FREEBOX\n//192.168.0.254/Disque\\ dur    /media/partage    cifs    guest,iocharset=utf8,gid=100,uid=1000,_netdev,file_mode=0777,dir_mode=0777,vers=2.0    0    0\n\n//192.168.0.254\\Disque\\ dur /media/freebox cifs _netdev,rw,users,credentials=/home/$USER/.smbcredentials,iocharset=utf8,uid=1000,sec=ntlmv2,file_mode=0777,dir_mode=0777,vers=2.00    0    0\n</code></pre> - uid=1000\u00a0indique l'id du user local (\u00e9viter les conflits de droits), - _netdev\u00a0fait attendre le montage que la partie r\u00e9seau soit d\u00e9marr\u00e9e, - rw\u00a0n'est plus n\u00e9cessaire (option par d\u00e9faut), - iocharset=utf8\u00a0est l'encodage de fichiers.</p> <p>Avant de red\u00e9marrer, il faut tester qu'il n'y a pas d'erreurs (sinon blocage boot) :</p> <pre><code>mount -a\n</code></pre> <p>Tout d\u00e9monter :</p> <pre><code>sudo umount -a -t cifs -l\n</code></pre> <p>Afin de tester le bon fonctionnement, je vous conseille de red\u00e9marrer votre machine et v\u00e9rifier que vous avez bien acc\u00e8s votre partage Freebox.</p>"},{"location":"post-install/data-storage/snapraid/","title":"SnapRAID","text":"<p>SnapRAID est un programme de sauvegarde con\u00e7u pour les baies de disques, stockant les informations de parit\u00e9 pour la r\u00e9cup\u00e9ration des donn\u00e9es en cas de panne de disque maximum.</p> <p>Principalement destin\u00e9 aux centres multim\u00e9dia domestiques avec des fichiers volumineux et rarement modifi\u00e9s, SnapRAID offre plusieurs fonctionnalit\u00e9s\u00a0:</p> <ul> <li>Vous pouvez utiliser des disques d\u00e9j\u00e0 remplis de fichiers sans avoir besoin de les reformater, en y acc\u00e9dant comme d'habitude,</li> <li>Toutes vos donn\u00e9es sont hach\u00e9es pour garantir leur int\u00e9grit\u00e9 et \u00e9viter toute corruption silencieuse,</li> <li>Lorsque le nombre de disques d\u00e9faillants d\u00e9passe le nombre de parit\u00e9, la perte de donn\u00e9es se limite aux disques concern\u00e9s ; les donn\u00e9es sur d'autres disques restent accessibles,</li> <li>Si vous supprimez accidentellement des fichiers sur un disque, la r\u00e9cup\u00e9ration est possible,</li> <li>Les disques peuvent avoir diff\u00e9rentes tailles,</li> <li>Vous pouvez ajouter des disques \u00e0 tout moment,</li> <li>SnapRAID ne verrouille pas vos donn\u00e9es\u00a0; vous pouvez arr\u00eater de l'utiliser \u00e0 tout moment sans reformater ni d\u00e9placer de donn\u00e9es,</li> <li>Pour acc\u00e9der \u00e0 un fichier, un seul disque doit tourner, ce qui permet d'\u00e9conomiser de l'\u00e9nergie et de r\u00e9duire le bruit.</li> </ul>"},{"location":"post-install/data-storage/snapraid/#installation","title":"Installation","text":"<p>SnapRAID ne fournit pas de packages, nous devons donc le compiler nous-m\u00eames \u00e0 partir des sources.</p> <p># ces \u00e9tapes supposent une installation Docker valide et fonctionnelle <pre><code>root@homelab:/# wget https://github.com/amadvance/snapraid/releases/download/v12.3/snapraid-12.3.tar.gz\nroot@homelab:/# tar xvf snapraid-12.3.tar.gz\nroot@homelab:/# cd snapraid-12.3\nroot@homelab:/# apt install build-essential\nroot@homelab:/# ./configure\nroot@homelab:/# make\nroot@homelab:/# make check\nroot@homelab:/# make install\n</code></pre></p> <p>V\u00e9rifiez l'installation r\u00e9ussie avec : <pre><code>root@homelab:/# snapraid --version\n</code></pre></p> <pre><code>root@homelab:~# snapraid smart\n\nSnapRAID SMART report:\n\n   Temp  Power   Error   FP Size\n      C OnDays   Count        TB  Serial               Device    Disk\n -----------------------------------------------------------------------\n      -      -       -    -  2.2  VB2ff4aa6e-3b5752ba  /dev/sdd  -\n      -      -       -    -  2.2  VBbc16d229-98501233  /dev/sde  -\n      -      -       -  SSD  1.1  VB4fd111ed-7ccb2978  /dev/sdb  -\n      -      -       -    -  2.2  VB41f1fa4d-a2c11c14  /dev/sdf  -\n      -      -       -    -  0.1  VBb598f427-91b62771  /dev/sdc  -\n      -      -       -  SSD  1.1  VB4d776a0a-b24c3eb0  /dev/sda  -\n\nThe FP column is the estimated probability (in percentage) that the disk\nis going to fail in the next year.\n\nProbability that at least one disk is going to fail in the next year is 0%.\n</code></pre>"},{"location":"post-install/data-storage/snapraid/#configuration","title":"Configuration","text":"<p>Cr\u00e9ation du fichier de configuration <code>/etc/snapraid.conf</code> : <pre><code># PR\u00c9REQUIS\nroot@homelab:/# mkdir /var/snapraid\n\n# CONFIGURATION\nroot@homelab:/# vi /etc/snapraid.conf\n\n# SnapRAID configuration file\n# Parity location(s)\nparity /mnt/parity/snapraid.parity\n\n# Content file location(s)\ncontent /var/snapraid.content\ncontent /mnt/data01/snapraid.content\ncontent /mnt/data02/snapraid.content\n\n# Data disks\ndata data01 /mnt/data01\ndata data02 /mnt/data02\n\n# Excludes hidden files and directories\nexclude *.unrecoverable\nexclude /tmp/\nexclude /lost+found/\nexclude downloads/\nexclude appdata/\nexclude *.!sync\nexclude .AppleDouble\nexclude ._AppleDouble\nexclude .DS_Store\nexclude ._.DS_Store\nexclude .Thumbs.db\nexclude .fseventsd\nexclude .Spotlight-V100\nexclude .TemporaryItems\nexclude .Trashes\nexclude .AppleDB\nexclude .nfo\n</code></pre></p> <p>On peut v\u00e9rifier le status de Snapraid apr\u00e8s la cr\u00e9ation du fichier de configuration : <pre><code>root@homelab:~# snapraid status\n\nSelf test...\nLoading state from /var/snapraid.content...\nWARNING! Content file '/var/snapraid.content' not found, attempting with another copy...\nLoading state from /mnt/data01/snapraid.content...\nWARNING! Content file '/mnt/data01/snapraid.content' not found, attempting with another copy...\nLoading state from /mnt/data02/snapraid.content...\nNo content file found. Assuming empty.\nUsing 0 MiB of memory for the file-system.\nSnapRAID status report:\n\n   Files Fragmented Excess  Wasted  Used    Free  Use Name\n            Files  Fragments  GB      GB      GB\n       0       0       0     0.0       0       -   -  data01\n       0       0       0     0.0       0       -   -  data02\n --------------------------------------------------------------------------\n       0       0       0     0.0       0       0   0%\n\nWARNING! Free space info will be valid after the first sync.\nThe array is empty.\n</code></pre></p> <p>\u00c0 ce stade, on est pr\u00eat \u00e0 lancer la commande <code>snapraid sync</code> pour cr\u00e9er les informations de parit\u00e9 : <pre><code>root@homelab:~# snapraid sync\n\nSelf test...\nLoading state from /var/snapraid.content...\nWARNING! Content file '/var/snapraid.content' not found, attempting with another copy...\nLoading state from /mnt/data01/snapraid.content...\nWARNING! Content file '/mnt/data01/snapraid.content' not found, attempting with another copy...\nLoading state from /mnt/data02/snapraid.content...\nNo content file found. Assuming empty.\nScanning...\nScanned d1 in 0 seconds\nScanned d2 in 0 seconds\nUsing 0 MiB of memory for the file-system.\nInitializing...\nResizing...\nSaving state to /var/snapraid.content...\nSaving state to /mnt/data01/snapraid.content...\nSaving state to /mnt/data02/snapraid.content...\nVerifying...\nVerified /var/snapraid.content in 0 seconds\nVerified /mnt/data01/snapraid.content in 0 seconds\nVerified /mnt/data02/snapraid.content in 0 seconds\nNothing to do\n</code></pre></p>"},{"location":"post-install/data-storage/snapraid/#automatisation-du-calcul-de-la-parite","title":"Automatisation du calcul de la parit\u00e9","text":"<p>Comme SnapRAID est con\u00e7u pour fonctionner en prenant des instantan\u00e9s, nous devons les configurer pour qu'ils soient calcul\u00e9s \u00e0 intervalles r\u00e9guliers. Nous pourrions simplement cr\u00e9er une t\u00e2che cron tr\u00e8s simple et ex\u00e9cuter la synchronisation Snapraid dans le cadre de ce processus, mais il y a quelques situations dans lesquelles nous voulons un peu plus d'intelligence qu'un simple cron.</p> <p>Pour ce faire, nous allons utiliser snapraid-runner qui est un utilitaire fiable pour ajouter des portes logiques \u00e0 l'ex\u00e9cution de SnapRAID.</p> <p>Ssnapraid-runner ex\u00e9cute Snapraid et envoie sa sortie \u00e0 la console, \u00e0 un fichier journal et par e-mail. Tout cela est configurable. Il peut \u00eatre ex\u00e9cut\u00e9 manuellement, mais son objectif principal est d'\u00eatre ex\u00e9cut\u00e9 via le planificateur cronjob de Linux ou encore Windows.</p> <p>Pour installer, on commence par cloner le d\u00e9p\u00f4t git\u00a0:</p> <pre><code>root@homelab:/# git clone https://github.com/Chronial/snapraid-runner.git /opt/snapraid-runner\n</code></pre> <p>Ensuite, on s'assure qu'on a bien configur\u00e9 le fichier de configuration de Snapraid :</p> <pre><code>root@homelab:/# cd /opt/snapraid-runner/\nroot@homelab:/opt/snapraid-runner# mv /opt/snapraid-runner/snapraid-runner.conf.example /opt/snapraid-runner/snapraid-runner.conf\nroot@homelab:/opt/snapraid-runner# vi snapraid-runner.conf\n\n[snapraid]\n; path to the snapraid executable (e.g. /bin/snapraid)\nexecutable = /usr/local/bin/snapraid\n; path to the snapraid config to be used\nconfig = /etc/snapraid.conf\n; abort operation if there are more deletes than this, set to -1 to disable\ndeletethreshold = 40\n; if you want touch to be ran each time\ntouch = true\n\n[logging]\n; logfile to write to, leave empty to disable\nfile = snapraid.log\n; maximum logfile size in KiB, leave empty for infinite\nmaxsize = 5000\n\n[email]\n; when to send an email, comma-separated list of [success, error]\nsendon = success,error\n; set to false to get full programm output via email\nshort = true\nsubject = [SnapRAID] Status Report:\nfrom =\nto =\n; maximum email size in KiB\nmaxsize = 500\n\n[smtp]\nhost = smtp.gmail.com\nport = 587\nssl = false\ntls = true\nuser = me@gmail.com\n# generate an app specific password : https://support.google.com/accounts/answer/185833?hl=en \npassword = password\n\n[scrub]\n; set to true to run scrub after sync\nenabled = true\n; scrub plan - either a percentage or one of [bad, new, full]\nplan = 12\n; minimum block age (in days) for scrubbing. Only used with percentage plans\nolder-than = 10\n</code></pre> <p>Modifiez le fichier de configuration pour snapraid-runner, un fichier par d\u00e9faut est fourni dans <code>/opt/snapraid-runner/snapraid-runner.conf.example</code>.</p> <p>Les param\u00e8tres suivants sont les plus int\u00e9ressants lors de la configuration de ce fichier\u00a0:</p> <ul> <li><code>config = /etc/snapraid.conf</code> - Assurez-vous que cela indique l'endroit o\u00f9 votre fichier <code>snapraid.conf</code> est stock\u00e9,</li> <li><code>deletethreshold = 40</code> - abandonner l'op\u00e9ration s'il y a plus de suppressions que cela, d\u00e9finir sur -1 pour d\u00e9sactiver,</li> <li><code>touch = True</code> - Cela am\u00e9liore la capacit\u00e9 de SnapRAID \u00e0 reconna\u00eetre les fichiers d\u00e9plac\u00e9s et copi\u00e9s, car cela rend l'horodatage presque unique, supprimant ainsi les doublons possibles,</li> <li><code>[email]</code> - Si vous utilisez Gmail, vous devrez g\u00e9n\u00e9rer un mot de passe sp\u00e9cifique \u00e0 l'application</li> <li><code>[scrub]</code> - Configurer les fonctionnalit\u00e9s de v\u00e9rification p\u00e9riodique des donn\u00e9es :<ul> <li><code>enabled = True</code></li> <li><code>plan = 12</code> - Le % du tableau \u00e0 nettoyer,</li> <li><code>older-than = 10</code> - Nettoyer les donn\u00e9es uniquement si elles datent de plus de ce nombre de jours.</li> </ul> </li> </ul> <p>Enfin, on cr\u00e9e une t\u00e2che cron pour ex\u00e9cuter automatiquement <code>snapraid-runner</code>. On doit s'assurer que les fichiers pour lesquels SnapRAID v\u00e9rifie la parit\u00e9 ne changent pas pendant cette p\u00e9riode. Id\u00e9alement, vers 4 ou 5 heures du matin, ce serait \u00e9galement une bonne id\u00e9e de d\u00e9sactiver temporairement tous les services qui \u00e9crivent sur votre stockage pendant cette p\u00e9riode - cela est cependant facultatif.</p> <pre><code>root@homelab:/# crontab -e\n\n00 01 * * * python3 /opt/snapraid-runner/snapraid-runner.py -c /opt/snapraid-runner/snapraid-runner.conf &amp;&amp; curl -fsS --retry 3 https://healthchecks.allfabox.fr/ &gt; /dev/null\n</code></pre> <p>Lors d'une synchronisation, SnapRAID \u00e9crira un fichier .content dans <code>/var/snapraid</code> et n\u00e9cessitera donc un acc\u00e8s en \u00e9criture \u00e0 ce r\u00e9pertoire. L'ex\u00e9cution via sudo ou en tant que root est ici une solution simple et fiable.</p> <p>Avec cron, c'est une bonne id\u00e9e d'\u00eatre aussi explicite que possible en ce qui concerne les chemins de fichiers. Ne vous fiez jamais aux chemins relatifs ou \u00e0 la variable <code>PATH</code>. Peut-\u00eatre avez-vous \u00e9galement remarqu\u00e9 qu'un contr\u00f4le de sant\u00e9 est configur\u00e9 sur hc-ping.com.</p>"},{"location":"post-install/data-storage/snapraid/#cas-dutilisation","title":"Cas d'utilisation","text":""},{"location":"post-install/data-storage/snapraid/#suppression-de-dossiersfichiers","title":"Suppression de dossiers/fichiers","text":"<p>Cela vous donnera le chemin absolu du point de vue du syst\u00e8me de fichiers\u00a0: </p> <pre><code>snapraid diff --test-fmt path\n</code></pre> <p>Cela vous permettra de conna\u00eetre le disque de donn\u00e9es du point de vue du tableau <code>Snapraid</code>\u00a0:</p> <pre><code>snapraid diff --test-fmt disk\n</code></pre> <p><code>Snapraid</code> ne s'attend pas \u00e0 ce que vous fournissiez le chemin absolu du syst\u00e8me de fichiers lors de la r\u00e9paration des fichiers.</p> <p>Cela recr\u00e9era tout fichier supprim\u00e9 dans l'ensemble du tableau\u00a0:</p> <pre><code>snapraid fix -m -v\n</code></pre> <p>Cela recr\u00e9era tout fichier supprim\u00e9 sur le disque de donn\u00e9es d1\u00a0:</p> <pre><code>snapraid fix -m -d d1\n</code></pre> <p>Cela recr\u00e9era le contenu de n'importe quel dossier nomm\u00e9 <code>sample</code> n'importe o\u00f9 dans le tableau\u00a0: <pre><code>snapraid fix -m -f sample/\n</code></pre></p> <p>Si vous n'\u00eates pas s\u00fbr de ce qui va se passer, vous pouvez remplacer fix par check ci-dessus et ajouter -v comme ceci\u00a0: <pre><code>snapraid check -m -f Example/ -v\n</code></pre></p> <p><code>Snapraid</code> vous dira alors qu'il y a un probl\u00e8me avec chacun des fichiers correspondant au filtre ou qu'ils sont ok.</p>"},{"location":"post-install/system/motd/","title":"Post-Installation - MOTD","text":""},{"location":"post-install/system/motd/#creer-un-motd-personnalise-ou-une-banniere-de-connexion-sous-linux","title":"Cr\u00e9er un MOTD<sup>1</sup> personnalis\u00e9 ou une banni\u00e8re de connexion sous Linux","text":"<p>Autrefois, avant les interfaces graphiques, les administrateurs syst\u00e8me laissaient un message aux utilisateurs en utilisant le fichier \u00ab MOTD \u00bb du message du jour. L'option motd est toujours disponible sur la plupart des syst\u00e8mes Linux modernes. Dans cet article, nous allons voir comment cr\u00e9er une jolie banni\u00e8re de connexion personnalis\u00e9e avec des illustrations ASCII et des informations syst\u00e8me.</p>"},{"location":"post-install/system/motd/#definition-dun-motd-de-texte-de-base-sous-linux","title":"D\u00e9finition d'un MOTD de texte de base sous Linux","text":"<p>Vous pouvez facilement d\u00e9finir un message texte de base du jour en \u00e9ditant le fichier /etc/motd. Tout texte que vous placez dans le fichier sera affich\u00e9 lors de la connexion de n'importe quel utilisateur.</p> <p>Exemple:</p> <pre><code>sudo vi /etc/motd\n#######################################\n# CECI EST UN MESSAGE DE TEST DANS /etc/motd #\n#######################################\n</code></pre> <p>D\u00e9sormais, lorsque quelqu'un se connectera via le terminal ou ssh, il verra le message. <pre><code>ssh monadresseip\nMot de passe de user@monadresseip :\n#######################################\n# CECI EST UN MESSAGE DE TEST DANS /etc/motd #\n#######################################\nDerni\u00e8re connexion : mardi 07 novembre 2023 11:44:58 \u00e0 partir du 91.184.102.244\n</code></pre></p> <p>Cela devrait fonctionner sur n'importe quelle machine Unix ou Linux, quelle que soit la distribution.</p>"},{"location":"post-install/system/motd/#script-de-connexion-personnalise-dans-le-profil-etc","title":"Script de connexion personnalis\u00e9 dans le profil Etc","text":"<p>Une autre option, plus flexible, consiste \u00e0 cr\u00e9er un script et \u00e0 le placer dans le dossier /etc/profile.d/. Tout script de ce dossier s'ex\u00e9cutera lorsqu'un utilisateur se connectera. </p> <p>L'utilisation d'un script dans /etc/profile.d vous offre des possibilit\u00e9s presque illimit\u00e9es. J'ai utilis\u00e9 un g\u00e9n\u00e9rateur d'art ASCII pour cr\u00e9er le nom de mon serveur via figurine et j'ai cr\u00e9\u00e9 cette banni\u00e8re de connexion : </p> <p>J'ai ensuite ajout\u00e9 la commande neofetch pour me montrer des informations sur le serveur.</p>"},{"location":"post-install/system/motd/#utilisation-de-figurine-pour-creer-lentete-de-la-banniere-de-connexion-personnalisee","title":"Utilisation de figurine pour cr\u00e9er l'ent\u00eate de la banni\u00e8re de connexion personnalis\u00e9e","text":"<p>figurine permet d'imprimer un texte avec style sur un terminal :  </p>"},{"location":"post-install/system/motd/#installation","title":"Installation","text":"<p>Vous pouvez t\u00e9l\u00e9charger le dernier binaire de Figurine ici :</p> <p>Ensuite : <pre><code>tar xzf https://github.com/arsham/figurine/releases/download/v1.3.0/figurine_linux_amd64_v1.3.0.tar.gz\nsudo chmod +x deploy/figurine\nmv deploy/figurine /usr/local/bin\nsudo rm -Rf deploy figurine_linux_amd64_v1.3.0.tar.gz\n</code></pre></p>"},{"location":"post-install/system/motd/#usage","title":"Usage","text":"<p>Chaque fois que l'application est appel\u00e9e, elle choisit une police al\u00e9atoire pour restituer le message. Passez le message que vous souhaitez d\u00e9corer comme arguments.</p> <pre><code>figurine Some Text\n</code></pre> <p>Vous pouvez imprimer les polices disponibles :</p> <pre><code>figurine -l\nfigurine -l -s\nfigurine -ls Sample Text\n</code></pre> <p>Pour d\u00e9finir une police :</p> <pre><code>figurine -f \"Poison.flf\" Some Text\n</code></pre> <p>Pour obtenir une liste des arguments disponibles :</p> <pre><code>figurine -h\n</code></pre>"},{"location":"post-install/system/motd/#utilisation-de-neofetch-pour-enrichir-la-banniere-de-connexion-personnalisee","title":"Utilisation de neofetch pour enrichir la banni\u00e8re de connexion personnalis\u00e9e","text":"<p>L'utilitaire neofetch est un outil de ligne de commande qui affiche le logo de distribution et les informations syst\u00e8me pour le syst\u00e8me sur lequel il est install\u00e9.</p> <p>Installation de l'utilitaire neofetch :</p> <p>Vous pouvez installer neofetch facilement avec la plupart des gestionnaires de packages.</p> <p>Pour installer neofetch sur Debian/Ubuntu : <pre><code>sudo apt-get install neofetch\n</code></pre></p> <p>Utiliser neofetch :</p> <p>Bien que neofetch ait une tonne d'options, il vous suffit de l'invoquer sans aucun argument pour obtenir un joli logo ascii et des informations syst\u00e8me (comme vu ci-dessus) :</p> <pre><code>neofetch\n</code></pre> <p>Pour utiliser neofetch comme banni\u00e8re de connexion, ex\u00e9cutez simplement la commande suivante pour cr\u00e9er un script qui s'ex\u00e9cute lors de la connexion.</p>"},{"location":"post-install/system/motd/#creation-du-script-etcprofiledmotdsh","title":"Cr\u00e9ation du script /etc/profile.d/motd.sh","text":"<pre><code>sudo vi /etc/profile.d/motd.sh\n</code></pre> <p>Ajoutez ces lignes : <pre><code>#!bin/bash\n\nfigurine -f \"3d.flf\" mon-serveur\nneofetch\n</code></pre></p> <p>On change les droits : <pre><code>sudo chmod +x /etc/profile.d/motd.sh\n</code></pre></p> <p>Par d\u00e9faut, le script est ex\u00e9cut\u00e9 \u00e0 la connexion de l'utilisateur via SSH.</p> <ol> <li> <p>Message of the Day - Message du jour\u00a0\u21a9</p> </li> </ol>"},{"location":"post-install/system/packages/","title":"Post-Installation - Utilitaires indispensables","text":""},{"location":"post-install/system/packages/#paquets-dans-les-depots","title":"Paquets dans les d\u00e9p\u00f4ts","text":"<pre><code>root@homelab:~#   apt install bash-completion \\\n    build-essential \\\n    curl \\\n    dnsutils \\\n    git \\\n    htop \\\n    ffmpeg \\\n    iftop \\\n    intel-gpu-tools \\\n    iotop \\\n    ipmitool \\\n    lm-sensors \\\n    mc \\\n    molly-guard \\\n    ncdu \\\n    net-tools \\\n    nfs-kernel-server \\\n    nmap \\\n    nvme-cli \\\n    openssh-server \\\n    python3 \\\n    qemu-guest-agent \\\n    sanoid \\\n    ssh-import-id \\\n    smartmontools \\\n    sudo \\\n    tree \\\n    vim \\\n    wget \\\n    zfsutils-linux\n</code></pre> <ul> <li><code>bash-completion</code> : compl\u00e9tions programmables pour l'interpr\u00e9teur bash,</li> <li><code>build-essential</code> : liste informative des paquets de construction essentiels,</li> <li><code>curl</code> : outil en ligne de commande pour transf\u00e9rer des donn\u00e9es avec une syntaxe URL,</li> <li><code>dnsutils</code> : Package de transition pour bind9-dnsutils - clients fournis par BIND 9,</li> <li><code>git</code> : syst\u00e8me de gestion de versions distribu\u00e9, rapide et \u00e9volutif,</li> <li><code>htop</code> : outil interactif de visualisation de processus,</li> <li><code>ffmpeg</code> : outils pour transcoder, diffuser en flux continu, et lire les fichiers multim\u00e9dia,</li> <li><code>iftop</code> : affichage d'informations sur l'utilisation de la bande passante d'une interface r\u00e9seau,</li> <li><code>intel-gpu-tools</code> : Outils de d\u00e9bogage des pilotes graphiques Intel,</li> <li><code>iotop</code> : moniteur simple des E/S dans le style de top,</li> <li><code>ipmitool</code> : utilitaire de contr\u00f4le IPMI avec pilote noyau ou interface r\u00e9seau,</li> <li><code>lm-sensors</code> : utilitaires pour lire les capteurs de temp\u00e9rature, tension et ventilateur,</li> <li><code>mc</code> : Midnight Commander - gestionnaire de fichiers \u00e9volu\u00e9,</li> <li><code>molly-guard</code> : protection de machines d\u2019arr\u00eats et de red\u00e9marrages accidentels,</li> <li><code>mutt</code> : outil de lecture de courriel en mode texte, g\u00e9rant MIME, GPG, PGP et les fils de discussion,</li> <li><code>ncdu</code> : visualiseur d'utilisation de disque avec ncurses,</li> <li><code>net-tools</code> : bo\u00eete \u00e0 outils NET-3 pour le r\u00e9seau,</li> <li><code>nfs-kernel-server</code> : gestion du serveur NFS du noyau,</li> <li><code>nmap</code> : Cartographe de r\u00e9seau,</li> <li><code>nvme-cli</code> : NVMe management tool,</li> <li><code>openssh-server</code> : serveur shell s\u00e9curis\u00e9 (SSH), pour acc\u00e8der \u00e0 des machines \u00e0 distance,</li> <li><code>python3</code> : langage orient\u00e9 objet interactif de haut niveau,</li> <li><code>python-setuptools</code> : am\u00e9liorations de Python Distutils,</li> <li><code>qemu-guest-agent</code> : Agent syst\u00e8me qemu c\u00f4t\u00e9 invit\u00e9,</li> <li><code>sanoid</code> : outil de gestion et de r\u00e9plication d'instantan\u00e9s ZFS bas\u00e9 sur des r\u00e8gles,</li> <li><code>screen</code> : multiplexeur d'\u00e9cran avec une \u00e9mulation de terminal VT100/ANSI,</li> <li><code>ssh-import-id</code> : r\u00e9cup\u00e9rer en toute s\u00e9curit\u00e9 une cl\u00e9 publique SSH et l'installer localement,</li> <li><code>smartmontools</code> : contr\u00f4le et surveillance de syst\u00e8mes de stockage utilisant S.M.A.R.T.,</li> <li><code>sudo</code> : fournit des privil\u00e8ges de super-utilisateurs \u00e0 des clients sp\u00e9cifiques,</li> <li><code>tmux</code> : multiplexeur de terminal,</li> <li><code>tree</code> : affichage d\u2019un arbre indent\u00e9 de r\u00e9pertoires, en couleur,</li> <li><code>vim</code> : \u00e9diteur vi am\u00e9lior\u00e9,</li> <li><code>wget</code> : r\u00e9cup\u00e9ration de fichiers sur le r\u00e9seau,</li> <li><code>wireguard-tools</code> : tunnel VPN du noyau rapide, moderne et s\u00e9curis\u00e9 (utilitaires de l'espace utilisateur),</li> <li><code>zfsutils-linux</code> : outils de ligne de commande pour g\u00e9rer les syst\u00e8mes de fichiers OpenZFS.</li> </ul>"},{"location":"post-install/system/packages/#duf-disk-usagefree-utility","title":"DUF - Disk Usage/Free Utility","text":"<p>R\u00e9f\u00e9rence : https://github.com/muesli/duf</p>"},{"location":"post-install/system/packages/#installation","title":"Installation","text":"<p>Next</p>"},{"location":"post-install/system/packages/#usage","title":"Usage","text":"<p>You can simply start duf without any command-line arguments:</p> <p>duf</p> <p>If you supply arguments, duf will only list specific devices &amp; mount points:</p> <p>duf /home /some/file</p> <p>If you want to list everything (including pseudo, duplicate, inaccessible file systems):</p> <p>duf --all</p> <p>Filtering</p> <p>You can show and hide specific tables:</p> <p>duf --only local,network,fuse,special,loops,binds duf --hide local,network,fuse,special,loops,binds</p> <p>You can also show and hide specific filesystems:</p> <p>duf --only-fs tmpfs,vfat duf --hide-fs tmpfs,vfat</p> <p>...or specific mount points:</p> <p>duf --only-mp /,/home,/dev duf --hide-mp /,/home,/dev</p> <p>Wildcards inside quotes work:</p> <p>duf --only-mp '/sys/,/dev/'</p> <p>Display options</p> <p>Sort the output:</p> <p>duf --sort size</p> <p>Valid keys are: mountpoint, size, used, avail, usage, inodes, inodes_used, inodes_avail, inodes_usage, type, filesystem.</p> <p>Show or hide specific columns:</p> <p>duf --output mountpoint,size,usage</p> <p>Valid keys are: mountpoint, size, used, avail, usage, inodes, inodes_used, inodes_avail, inodes_usage, type, filesystem.</p> <p>List inode information instead of block usage:</p> <p>duf --inodes</p> <p>If duf doesn't detect your terminal's colors correctly, you can set a theme:</p> <p>duf --theme light</p> <p>Color-coding &amp; Thresholds</p> <p>duf highlights the availability &amp; usage columns in red, green, or yellow, depending on how much space is still available. You can set your own thresholds:</p> <p>duf --avail-threshold=\"10G,1G\" duf --usage-threshold=\"0.5,0.9\"</p> <p>Bonus</p> <p>If you prefer your output as JSON:</p> <p>duf --json</p>"},{"location":"post-install/system/postgresql/","title":"Post-Installation - Base de donn\u00e9es PostgreSQL","text":""},{"location":"post-install/system/postgresql/#postgresql-sur-un-dataset-zfs","title":"PostgreSQL sur un dataset ZFS","text":"<p>Ma r\u00e9flexion ici est de profiter du pool ZFS en mirroir <code>rpool</code> cr\u00e9\u00e9 \u00e0 l'installation de Proxmox dans le but d'y stocker les donn\u00e9es du cluster PotsgreSQL et de profiter des <code>snapshots</code> de ZFS. De plus, on profitera aussi des performances des disques NVMe en mirroir sur lequel est cr\u00e9\u00e9 le pool <code>rpool</code>.</p> <p>Pour cela, je vais cr\u00e9er un container LCX qui va faire tourner PostgreSQL et utiliser les options de point de montage des containers LXC pour mapper un dataset ZFS que je vais cr\u00e9er en amont et le mapper sur <code>/var/lib/postgresql</code> de mon container.</p> <p>On n'oubliera pas de cr\u00e9er un petit script de sauvegarde des donn\u00e9es via <code>pg_dump</code> ou autre afin de pouvoir remonter une base en cas de soucis, mais dans un premier temps, on pourra tirer profit de la gestion de rollback des snapshots ZFS.</p>"},{"location":"post-install/system/postgresql/#visualisation-du-pool-zfs","title":"Visualisation du pool ZFS","text":"<pre><code>root@homelab:~# zpool status\n  pool: rpool\n state: ONLINE\n  scan: scrub repaired 0B in 00:00:34 with 0 errors on Fri Mar 15 14:31:08 2024\nconfig:\n\n        NAME                                             STATE     READ WRITE CKSUM\n        rpool                                            ONLINE       0     0     0\n          mirror-0                                       ONLINE       0     0     0\n            ata-VBOX_HARDDISK_VB4d776a0a-b24c3eb0-part3  ONLINE       0     0     0\n            ata-VBOX_HARDDISK_VB4fd111ed-7ccb2978-part3  ONLINE       0     0     0\n\nerrors: No known data errors\n\nroot@homelab:~# zfs list\nNAME               USED  AVAIL  REFER  MOUNTPOINT\nrpool             1.70G   983G   104K  /rpool\nrpool/ROOT        1.70G   983G    96K  /rpool/ROOT\nrpool/ROOT/pve-1  1.70G   983G  1.70G  /\nrpool/data          96K   983G    96K  /rpool/data\nrpool/var-lib-vz    96K   983G    96K  /var/lib/vz\n</code></pre>"},{"location":"post-install/system/postgresql/#creation-de-lensemble-de-donnees-dataset-sur-le-pool-zfs-rpool","title":"Cr\u00e9ation de l'ensemble de donn\u00e9es (dataset) sur le pool ZFS <code>rpool</code>","text":"<pre><code>root@homelab:~# zfs create rpool/pgdata -o mountpoint=/var/lib/postgresql\nroot@homelab:~# zfs list\nNAME               USED  AVAIL  REFER  MOUNTPOINT\nrpool             1.70G   983G   104K  /rpool\nrpool/ROOT        1.70G   983G    96K  /rpool/ROOT\nrpool/ROOT/pve-1  1.70G   983G  1.70G  /\nrpool/data          96K   983G    96K  /rpool/data\nrpool/pgdata        96K   983G    96K  /var/lib/postgresql\nrpool/var-lib-vz    96K   983G    96K  /var/lib/vz\n</code></pre>"},{"location":"post-install/system/postgresql/#options-du-pool-zfs-rpoolpgdata","title":"Options du pool ZFS <code>rpool/pgdata</code>","text":"<pre><code># On active la compression\nroot@homelab:~# zfs set compression=lz4 rpool/pgdata\n\n# On d\u00e9sactive le temps d'acc\u00e8s (trop d'\u00e9critures...)\nroot@homelab:~# zfs set atime=off rpool/pgdata\n\n# On active les attributs \u00e9tendus am\u00e9lior\u00e9s\nroot@homelab:~# zfs set xattr=sa rpool/pgdata\n\n# Je laisse la valeur par d\u00e9faut de 128 Ko et voir comment \u00e7a se passe. \nroot@homelab:~#  zfs set recordsize=128k rpool/pgdata\n# Les nombres inf\u00e9rieurs sont potentiellement plus rapides, mais les nombres plus \u00e9lev\u00e9s\n# ont tendance \u00e0 obtenir une meilleure compression.\n</code></pre>"},{"location":"post-install/system/postgresql/#configuration-systeme","title":"Configuration syst\u00e8me","text":"<pre><code># On notifie \u00e0 Linux de ne pas utiliser le swap sauf en cas d'absolue n\u00e9cessit\u00e9\nroot@homelab:~#  sysctl -w vm.swappiness=1\n# Ajoutez 'vm.swappiness=1' \u00e0 systctl.conf pour un effet permanent  \nroot@homelab:~#  echo 'vm.swappiness=1' | tee -a /etc/sysctl.conf\n</code></pre>"},{"location":"post-install/system/postgresql/#installation-de-potgresql-sur-un-container-lxc","title":"Installation de PotgreSQL sur un container LXC","text":"<p>Avant de pouvoir configurer un ensemble de donn\u00e9es ZFS (dataset), nous devons installer/configurer Postgres sur un container LXC sous Debian.</p> <p>Postgres doit ex\u00e9cuter son <code>init</code> avant d'\u00eatre d\u00e9placer vers un dataset ZFS. <pre><code>root@homelab:~# sh -c 'echo \"deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main\" &gt; /etc/apt/sources.list.d/pgdg.list'\nroot@homelab:~# wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | apt-key add -\nroot@homelab:~# apt update &amp;&amp; apt install postgresql-16 postgresql-contrib-16\n</code></pre></p> <p>Ensuite, il faut stoper le service <code>postgres</code>, d\u00e9placez ses donn\u00e9es vers un emplacement temporaire, cr\u00e9ez l'ensemble de donn\u00e9es ZFS et d\u00e9placez les \u00e9l\u00e9ments \u00e0 nouveau. <pre><code>root@homelab:~# systemctl stop postgresql\n\n# D\u00e9placer les donn\u00e9es postgres vers temp\nroot@homelab:~# mv /var/lib/postgresql/16/main/pg_wal /tmp/pg_wal\nroot@homelab:~# mv /var/lib/postgresql /tmp/postgresql\n\n# Cr\u00e9ation du dataset ZFS\nroot@homelab:~# zfs create postgres/data -o mountpoint=/var/lib/postgresql\nroot@homelab:~# zfs create postgres/wal -o mountpoint=/var/lib/postgresql/16/main/pg_wal\n\n# On recopie/red\u00e9place le cluster postgres initial\nroot@homelab:~# cp -r /tmp/postgresql/* /var/lib/postgresql\nroot@homelab:~# cp -r /tmp/pg_wal/* /var/lib/postgresql/16/main/pg_wal\n\n#R\u00e9actulisation des permissions\nroot@homelab:~# chmod -R 0700 /var/lib/postgresql\nroot@homelab:~# chmod -R 0700 /var/lib/postgresql/16/main/pg_wal\nroot@homelab:~# chown -R postgres: /var/lib/postgresql\n\n# D\u00e9marrage du service Postgresql\nroot@homelab:~# systemctl start postgresql\n</code></pre></p>"},{"location":"post-install/system/postgresql/#configuration-postgresql","title":"Configuration PostgreSQL","text":"<p>On \u00e9dite le fichier <code>/etc/postgresql/16/main/postgresql.conf</code> pour d\u00e9finir <code>full_page_writes = off</code> du c\u00f4t\u00e9 postgres. ZFS ne peut pas \u00e9crire de pages partielles, donc c'est assez redondant. <pre><code>root@homelab:~#  /etc/postgresql/16/main/postgresql.conf\n\nfull_page_writes = off\n</code></pre></p>"},{"location":"post-install/system/postgresql/#point-de-montage-zfs","title":"Point de montage ZFS","text":"<p>Ajout du point de montage sur le container LXC apr\u00e8s l'installation de PotgreSQL sur le container (penser \u00e0 stopper le service postgres)</p> <p><code>pct set &lt;ID&gt; -mp0 /host/dir,mp=/container/mount/point</code></p> <pre><code>root@homelab:~#  pct set 101 -mp0 /var/lib/postgresql,mp=/var/lib/postgresql\n</code></pre>"},{"location":"post-install/system/postgresql/#gestion-des-droits-entre-proxmox-et-le-container-lxc","title":"Gestion des droits entre Proxmox et le container LXC","text":"<p>Gestion des droits entre l'host Proxmox et le container LXC sur lequel les donn\u00e9es vont \u00eatre mont\u00e9es</p> <pre><code>root@homelab:~#  chown -Rf 10000:10000 /var/lib/postgresql\n</code></pre>"},{"location":"post-install/system/postgresql/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Our Experience with PostgreSQL on ZFS </li> <li>Running bare metal PostgreSQL on ZFS</li> <li>Proxmox: bind mountpoint from host to unprivileged LXC container</li> </ul>"},{"location":"post-install/system/proxmox/","title":"POST-INSTALLATION - Proxmox - Configuration","text":""},{"location":"post-install/system/proxmox/#desactiver-les-depots-pve-enterprise-et-ceph","title":"D\u00e9sactiver les d\u00e9p\u00f4ts pve-enterprise et ceph","text":"<p>La premi\u00e8re chose \u00e0 faire dans la configuration de Proxmox, est de d\u00e9sactiver le d\u00e9p\u00f4t PVE Entreprise et Ceph si on n'en a pas l'utilit\u00e9.</p> <p>On peut le faire de 2 fa\u00e7ons diff\u00e9rentes :</p> <ul> <li>Via l'interface graphique</li> <li>Ou en ligne de commande</li> </ul>"},{"location":"post-install/system/proxmox/#via-linterface-graphique","title":"Via l'interface graphique","text":"<p>Se rendre sous homelab &gt; Updates &gt; Repositories :</p> homelab &gt; Updates &gt; Repositories <p>Pour le d\u00e9pot https://entreprise.proxmox.com/debian/pve :</p> On retrouve cette interface On s\u00e9lectionne la ligne https://entreprise.proxmox.com/debian/pve et on la d\u00e9sactive en cliquant sur le bouton Disable qui se trouve au-dessus <p>Pour le d\u00e9pot https://entreprise.proxmox.com/debian/ceph-quincy :</p> <p>On r\u00e9it\u00e8re les \u00e9tapes ci-dessus en prenant le soin de bien s\u00e9lectionner le d\u00e9p\u00f4t https://entreprise.proxmox.com/debian/ceph-quincy</p>"},{"location":"post-install/system/proxmox/#en-ligne-de-commande","title":"En ligne de commande","text":"<p>On se connect en SSH sur le serveur Proxmox ou via le Shell sur l'interface graphique.  On va venir \u00e9diter ce fichier et commenter la ligne : <pre><code>$ vi /etc/apt/sources.list.d/pve-enterprise.list\n\n# deb https://enterprise.proxmox.com/debian/pve bookworm pve-enterprise\n</code></pre>  Pareil pour le d\u00e9p\u00f4t Ceph : <pre><code>$ vi /etc/apt/sources.list.d/ceph.list\n\n# deb https://enterprise.proxmox.com/debian/ceph-quincy bookworm enterprise\n</code></pre></p>"},{"location":"post-install/system/proxmox/#activer-le-depot-pve-no-subscription","title":"Activer le d\u00e9p\u00f4t pve-no-subscription","text":"XXXXX"},{"location":"post-install/system/proxmox/#desactiver-le-stockage-par-defaut-local","title":"D\u00e9sactiver le stockage par d\u00e9faut local","text":"Stockage \u00e0 d\u00e9sactiver"},{"location":"post-install/system/proxmox/#via-linterface-graphique_1","title":"Via l'interface graphique","text":"<p>On s\u00e9lectionne la ligne correspondant au stockage que l'on veut d\u00e9sactiver, on clique sur <code>Edit</code> et on d\u00e9coche <code>Enable</code> et on valide.</p>"},{"location":"post-install/system/proxmox/#en-ligne-de-commande_1","title":"En ligne de commande","text":"<p>Pour d\u00e9sactiver le stockage <code>local</code> sur <code>/var/lib/vz</code> : <pre><code>$ pvesm set local --disable 0\n</code></pre></p> <p>Pour activer le stockage <code>local</code> sur <code>/var/lib/vz</code> : <pre><code>$ pvesm set local --disable 0\n</code></pre></p> <p>R\u00e9f\u00e9rence : https://pve.proxmox.com/wiki/Storage#_using_the_command_line_interface</p>"},{"location":"post-install/system/proxmox/#proxmox-et-lvm","title":"Proxmox et LVM","text":""},{"location":"post-install/system/proxmox/#de-lutilisation-du-volume-logique-devpvedata","title":"De l'utilisation du volume logique <code>/dev/pve/data</code>","text":"<p>Le programme d'installation cr\u00e9e un groupe de volumes (VG) appel\u00e9 pve et des volumes logiques (LV) suppl\u00e9mentaires appel\u00e9s root, data et swap. </p> <p>Pour contr\u00f4ler la taille de ces volumes, Proxmox utilise les options suivantes :</p> <p><code>hdsize</code> : D\u00e9finit la taille totale du disque dur \u00e0 utiliser. De cette fa\u00e7on, vous pouvez r\u00e9server de l'espace libre sur le disque dur pour un partitionnement ult\u00e9rieur (par exemple pour un PV et un VG suppl\u00e9mentaires sur le m\u00eame disque dur pouvant \u00eatre utilis\u00e9s pour le stockage LVM).  </p> <p><code>swapsize</code> : D\u00e9finit la taille du volume de swap. La valeur par d\u00e9faut est la taille de la m\u00e9moire install\u00e9e, minimum 4 Go et maximum 8 Go. La valeur r\u00e9sultante ne peut pas \u00eatre sup\u00e9rieure \u00e0 hdsize/8. </p> <p>Remarque : Si la valeur est 0, aucun volume d'\u00e9change ne sera cr\u00e9\u00e9. </p> <p><code>maxroot</code> : D\u00e9finit la taille maximale du volume racine, qui stocke le syst\u00e8me d'exploitation. La limite maximale de la taille du volume racine est hdsize/4.  </p> <p><code>maxvz</code> : D\u00e9finit la taille maximale du volume de donn\u00e9es. La taille r\u00e9elle du volume de donn\u00e9es est\u00a0:  <code>datasize = hdsize - rootsize - swapsize - minfree</code></p> <p>O\u00f9 la taille des donn\u00e9es ne peut pas \u00eatre sup\u00e9rieure \u00e0 maxvz.  </p> <p>Note</p> <p>Remarque : En cas de LVM Thin, le pool de donn\u00e9es ne sera cr\u00e9\u00e9 que si la taille des donn\u00e9es est sup\u00e9rieure \u00e0 4 Go. Remarque : Si la valeur est 0, aucun volume de donn\u00e9es ne sera cr\u00e9\u00e9 et la configuration du stockage sera adapt\u00e9e en cons\u00e9quence.</p> <p><code>minfree</code> : D\u00e9finit la quantit\u00e9 d'espace libre restant dans le groupe de volumes LVM <code>pve</code>. Avec plus de 128 Go de stockage disponible, la valeur par d\u00e9faut est 16 Go, sinon hdsize/8 sera utilis\u00e9. Remarque : LVM n\u00e9cessite de l'espace libre dans le VG pour la cr\u00e9ation d'instantan\u00e9s (non requis pour les instantan\u00e9s lvmthin).</p> <p>Note</p> <p>Avec cette configuration, on n'a pas totalement la main sur la taille des volumes logiques cr\u00e9\u00e9s. La suite de cette documentation d\u00e9taille comment supprimer le volume logique <code>/dev/pve/data</code> et de r\u00e9cup\u00e9rer l'espace disque suppl\u00e9mentaire pour agrandir le volume logique <code>/dev/pve/root</code>. Noter qur nous utiliserons un disque dur compl\u00e9mentaire afin de recr\u00e9er un volume logique <code>/dev/pve/data</code>.</p> <p>Avertissement</p> <p>Ces op\u00e9rations doivent \u00eatre r\u00e9alis\u00e9es sur une installation initiale et avec pr\u00e9caution. \u00c0 ne pas faire sur une installation de <code>Proxmox</code> en production.</p>"},{"location":"post-install/system/proxmox/#suppression-du-volume-logique-data-et-extension-du-volume-logique-root-avec-lespace-disque-libere","title":"Suppression du volume logique <code>data</code> et extension du volume logique <code>root</code> avec l'espace disque lib\u00e9r\u00e9","text":"<p>D\u00e9sactivation du volume logique <code>/dev/pve/data</code> et suppression du volume logique : <pre><code>lvchange -an /dev/pve/data\nlvremove /dev/pve/data\n</code></pre></p> <p>Agrandir le volume logique <code>/dev/pve/root</code> avec l'espace disque lib\u00e9r\u00e9 par la suppression du volume logique <code>/dev/pve/data</code> <pre><code>lvextend -l +100%FREE /dev/pve/root\n</code></pre></p> <p>Il faut maintenant penser \u00e0 agrandir le syst\u00e8me de fichier du volume logique <code>/dev/pve/root</code>.  V\u00e9rification du syst\u00e8me de fichier utilis\u00e9 sur <code>/dev/pve/root</code> : <pre><code>lsblk -o NAME,TYPE,MOUNTPOINT,FSTYPE,FSSIZE,SIZE,FSAVAIL\n\nNAME         TYPE MOUNTPOINT FSTYPE      FSSIZE  SIZE FSAVAIL\nsda          disk                                 60G \n\u251c\u2500sda1       part                               1007K \n\u251c\u2500sda2       part            vfat                512M \n\u2514\u2500sda3       part            LVM2_member        59.5G \n  \u251c\u2500pve-swap lvm  [SWAP]     swap                  8G \n  \u2514\u2500pve-root lvm  /          ext4         24.3G 51.5G   19.4G\nsdb          disk                                128G \n</code></pre></p> <p>Le syst\u00e8me de fichier <code>/dev/pve/root</code> est en <code>ext4</code>. On r\u00e9alise l'agrandissement \u00e0 chaud sans d\u00e9monter le volume : <pre><code>resize2fs /dev/pve/root\n</code></pre></p> <pre><code>lsblk -o NAME,TYPE,MOUNTPOINT,FSTYPE,FSSIZE,SIZE,FSAVAIL\n\nNAME         TYPE MOUNTPOINT FSTYPE      FSSIZE  SIZE FSAVAIL\nsda          disk                                 60G \n\u251c\u2500sda1       part                               1007K \n\u251c\u2500sda2       part            vfat                512M \n\u2514\u2500sda3       part            LVM2_member        59.5G \n  \u251c\u2500pve-swap lvm  [SWAP]     swap                  8G \n  \u2514\u2500pve-root lvm  /          ext4         50.5G 51.5G   44.6G\nsdb          disk                                128G \n</code></pre>"},{"location":"post-install/system/proxmox/#creation-du-volume-logique-devpvedata-sur-un-disque-dur-prevu-a-cet-effet-devsdb","title":"Cr\u00e9ation du volume logique <code>/dev/pve/data</code> sur un disque dur pr\u00e9vu \u00e0 cet effet <code>/dev/sdb</code>","text":"<p>Etat des lieux <code>LVM</code>: <pre><code>pvdisplay\n\n--- Physical volume ---\n  PV Name               /dev/sda3\n  VG Name               pve\n  PV Size               &lt;63.50 GiB / not usable 2.98 MiB\n  Allocatable           yes (but full)\n  PE Size               4.00 MiB\n  Total PE              16255\n  Free PE               0\n  Allocated PE          16255\n  PV UUID               QCTN2f-GNZR-TWsG-q8IR-3Jr0-ztd2-6fQjJ6\n</code></pre></p> <pre><code>vgdisplay \n\n  --- Volume group ---\n  VG Name               pve\n  System ID             \n  Format                lvm2\n  Metadata Areas        1\n  Metadata Sequence No  9\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                2\n  Open LV               2\n  Max PV                0\n  Cur PV                1\n  Act PV                1\n  VG Size               &lt;63.50 GiB\n  PE Size               4.00 MiB\n  Total PE              16255\n  Alloc PE / Size       16255 / &lt;63.50 GiB\n  Free  PE / Size       0 / 0   \n  VG UUID               nQPS3U-LCV8-1K91-gM7K-j0W6-3aEx-92QrCt\n</code></pre> <pre><code>lvdisplay\n\n--- Logical volume ---\n  LV Path                /dev/pve/swap\n  LV Name                swap\n  VG Name                pve\n  LV UUID                bKPvlf-nqi2-jiNH-X4Fe-pkbO-P3Oo-Smto3f\n  LV Write Access        read/write\n  LV Creation host, time proxmox, 2024-12-18 14:35:01 +0100\n  LV Status              available\n  # open                 2\n  LV Size                8.00 GiB\n  Current LE             2048\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           252:0\n\n  --- Logical volume ---\n  LV Path                /dev/pve/root\n  LV Name                root\n  VG Name                pve\n  LV UUID                CnnWlY-8tSq-H8Ec-eQVw-m8FM-lNU7-VIzr0J\n  LV Write Access        read/write\n  LV Creation host, time proxmox, 2024-12-18 14:35:01 +0100\n  LV Status              available\n  # open                 1\n  LV Size                &lt;55.50 GiB\n  Current LE             14207\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           252:1\n</code></pre> <p>Agrandissement du groupe de volume <code>pve</code> avec la partition <code>/dev/sdb1</code> du disque dur <code>/dev/sdb</code> : <pre><code>lsblk -o NAME,TYPE,MOUNTPOINT,FSTYPE,FSSIZE,SIZE,FSAVAIL\n\nNAME         TYPE MOUNTPOINT FSTYPE      FSSIZE  SIZE FSAVAIL\nsda          disk                                 64G \n\u251c\u2500sda1       part                               1007K \n\u251c\u2500sda2       part            vfat                512M \n\u2514\u2500sda3       part            LVM2_member        63.5G \n  \u251c\u2500pve-swap lvm  [SWAP]     swap                  8G \n  \u2514\u2500pve-root lvm  /          ext4         54.4G 55.5G   48.2G\nsdb          disk                                128G \n\u2514\u2500sdb1       part                                128G \n</code></pre></p> <pre><code>vgextend pve /dev/sdb1\nPhysical volume \"/dev/sdb1\" successfully created.\n  Volume group \"pve\" successfully extended\n\nvgdisplay\n--- Volume group ---\n  VG Name               pve\n  System ID             \n  Format                lvm2\n  Metadata Areas        2\n  Metadata Sequence No  10\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                2\n  Open LV               2\n  Max PV                0\n  Cur PV                2\n  Act PV                2\n  VG Size               191.49 GiB\n  PE Size               4.00 MiB\n  Total PE              49022\n  Alloc PE / Size       16255 / &lt;63.50 GiB\n  Free  PE / Size       32767 / &lt;128.00 GiB\n  VG UUID               nQPS3U-LCV8-1K91-gM7K-j0W6-3aEx-92QrCt\n</code></pre> <p>Cr\u00e9ation du volume logique <code>/dev/pve/data</code> de type <code>thin-pool</code> : <pre><code>lvcreate -l 100%FREE --thin --name data pve\n\nThin pool volume with chunk size 64.00 KiB can address at most &lt;15.88 TiB of data.\nLogical volume \"data\" created.\n\nlvs\n  LV   VG  Attr       LSize    Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert\n  data pve twi-a-tz-- &lt;127.75g             0.00   10.42                           \n  root pve -wi-ao----  &lt;55.50g                                                    \n  swap pve -wi-ao----    8.00g\n</code></pre></p> <p>Ajout du stockage de type LVM <code>thin-pool</code> dans Proxmox : <pre><code># add the storage in to Proxmox CV as an LVM Thin type named \"local-lvm\"\npvesm add lvmthin local-lvm -vgname pve -thinpool data\n</code></pre></p>"},{"location":"post-install/system/proxmox/#stocker-les-images-iso-des-vmscts","title":"Stocker les images iso des VMS/CTs","text":"<p>Afin de ne pas surcharger les espaces de stockage de Proxmox, j'ai opt\u00e9 pour la mise en place d'un stockage sur cl\u00e9 USB pour stocker les images ISOs des VMs ou encore mes templates de les containers LXC.</p> <p>A cette fin, il faut brancher un\u00e9 cl\u00e9 USB sur la machine. Moi, j'ai opt\u00e9 pour un\u00e9 cl\u00e9 USB 3.2 SanDisk Ultra Fit de 128GO que j'ai branch\u00e9 au cul de mon serveur. Ce ne sont pas des donn\u00e9es tr\u00e8s sensibles, si ma cl\u00e9 venait \u00e0 rendre l'\u00e2me, ce sont des donn\u00e9es facilement rempla\u00e7ables.</p> <p>Proc\u00e9dure :</p> <ul> <li>Branchez la cl\u00e9 USB sur le serveur,</li> <li> <p>Sur le serveur Proxmox, lancez la commande pour d\u00e9t\u00e9cter/identifier le mat\u00e9riel fra\u00eechement ajout\u00e9 : <pre><code>root@homelab:~# fdisk -l\nDisk /dev/sda: 1 TiB, 1099511627776 bytes, 2147483648 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: 30CEC8C0-5E64-4538-BCB6-14419B0A845D\n\nDevice       Start        End    Sectors  Size Type\n/dev/sda1       34       2047       2014 1007K BIOS boot\n/dev/sda2     2048    2099199    2097152    1G EFI System\n/dev/sda3  2099200 2147483614 2145384415 1023G Solaris /usr &amp; Apple ZFS\n\n\nDisk /dev/sdb: 1 TiB, 1099511627776 bytes, 2147483648 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: 1938A24D-F234-4DAE-958D-964B26179408\n\nDevice       Start        End    Sectors  Size Type\n/dev/sdb1       34       2047       2014 1007K BIOS boot\n/dev/sdb2     2048    2099199    2097152    1G EFI System\n/dev/sdb3  2099200 2147483614 2145384415 1023G Solaris /usr &amp; Apple ZFS\n\n\nDisk /dev/sdc: 128 GiB, 137438953472 bytes, 268435456 sectors\nDisk model: VBOX HARDDISK   \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n</code></pre></p> </li> <li> <p>On remarque que notre cl\u00e9 est identifi\u00e9e sur <code>/dev/sdc</code>. On va donc formater la cl\u00e9 et la monter.</p> </li> <li>Cr\u00e9er une table de partition GPT avec sgdisk : <pre><code>root@homelab:~# sgdisk -o /dev/sdc\nCreating new GPT entries in memory.\nThe operation has completed successfully.\n</code></pre></li> </ul> <p>Note</p> <p>Lorsqu'il est invoqu\u00e9 avec l'option <code>-o</code> (ou <code>--clear</code>), <code>sgdisk</code> efface toute table de partition existante sur le p\u00e9riph\u00e9rique donn\u00e9 et cr\u00e9e une nouvelle table de partition GPT. Encore une fois, puisque le programme est destin\u00e9 \u00e0 \u00eatre utilis\u00e9 \u00e0 partir de scripts, aucun avertissement ne sera \u00e9mis et aucune confirmation ne sera demand\u00e9e, il doit donc \u00eatre utilis\u00e9 avec pr\u00e9caution.</p> <ul> <li> <p>Formatage de la cl\u00e9 :   <pre><code>root@homelab:~# mkfs.ext4 /dev/sdc\nmke2fs 1.47.0 (5-Feb-2023)\nFound a gpt partition table in /dev/sdc\nProceed anyway? (y,N) y\nCreating filesystem with 33554432 4k blocks and 8388608 inodes\nFilesystem UUID: 01418e86-d606-4d40-acf4-79af5045172c\nSuperblock backups stored on blocks: \n        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, \n        4096000, 7962624, 11239424, 20480000, 23887872\n\nAllocating group tables: done                            \nWriting inode tables: done                            \nCreating journal (262144 blocks): done\nWriting superblocks and filesystem accounting information: done\n</code></pre></p> </li> <li> <p>Cr\u00e9\u00e9 un point de montage et monter la cl\u00e9 : <pre><code>root@homelab:~# mkdir /mnt/iso\nroot@homelab:~# mount /dev/sdc /mnt/iso\nroot@homelab:~# df -h\nFilesystem        Size  Used Avail Use% Mounted on\nudev              3.9G     0  3.9G   0% /dev\ntmpfs             794M  792K  793M   1% /run\nrpool/ROOT/pve-1  985G  1.7G  983G   1% /\ntmpfs             3.9G   43M  3.9G   2% /dev/shm\ntmpfs             5.0M     0  5.0M   0% /run/lock\nrpool             983G  128K  983G   1% /rpool\nrpool/var-lib-vz  983G  128K  983G   1% /var/lib/vz\nrpool/ROOT        983G  128K  983G   1% /rpool/ROOT\nrpool/data        983G  128K  983G   1% /rpool/data\n/dev/fuse         128M   16K  128M   1% /etc/pve\ntmpfs             794M     0  794M   0% /run/user/0\n/dev/sdc          125G   28K  119G   1% /mnt/iso\n</code></pre> On retrouve bien notre cl\u00e9 USB mont\u00e9e sur <code>/mnt/iso</code>. \u00c0 ce stade, le point de montage est \u00e9ph\u00e9m\u00e8re. Si jamais la machine red\u00e9marre, la cl\u00e9 USB ne sera pas remont\u00e9e automatquement sur <code>/mnt/iso</code>. Pour cela, il faut \u00e9diter le fichier <code>/etc/fstab</code>.</p> </li> <li> <p>Rendre persistent le montage via <code>/etc/fstab</code> et l'D du disque : <pre><code>root@homelab:~# ls -al /dev/disk/by-id/\ntotal 0\ndrwxr-xr-x 2 root root 220 Mar 15 15:22 .\ndrwxr-xr-x 8 root root 160 Mar 15 14:54 ..\nlrwxrwxrwx 1 root root   9 Mar 15 14:54 ata-VBOX_HARDDISK_VB4d776a0a-b24c3eb0 -&gt; ../../sda\nlrwxrwxrwx 1 root root  10 Mar 15 14:54 ata-VBOX_HARDDISK_VB4d776a0a-b24c3eb0-part1 -&gt; ../../sda1\nlrwxrwxrwx 1 root root  10 Mar 15 14:54 ata-VBOX_HARDDISK_VB4d776a0a-b24c3eb0-part2 -&gt; ../../sda2\nlrwxrwxrwx 1 root root  10 Mar 15 14:54 ata-VBOX_HARDDISK_VB4d776a0a-b24c3eb0-part3 -&gt; ../../sda3\nlrwxrwxrwx 1 root root   9 Mar 15 14:54 ata-VBOX_HARDDISK_VB4fd111ed-7ccb2978 -&gt; ../../sdb\nlrwxrwxrwx 1 root root  10 Mar 15 14:54 ata-VBOX_HARDDISK_VB4fd111ed-7ccb2978-part1 -&gt; ../../sdb1\nlrwxrwxrwx 1 root root  10 Mar 15 14:54 ata-VBOX_HARDDISK_VB4fd111ed-7ccb2978-part2 -&gt; ../../sdb2\nlrwxrwxrwx 1 root root  10 Mar 15 14:54 ata-VBOX_HARDDISK_VB4fd111ed-7ccb2978-part3 -&gt; ../../sdb3\nlrwxrwxrwx 1 root root   9 Mar 15 15:22 ata-VBOX_HARDDISK_VBb598f427-91b62771 -&gt; ../../sdc\n</code></pre> <pre><code>root@homelab:~# vi /etc/fstab\n# &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt;\nproc /proc proc defaults 0 0\n\n# /mnt/iso\n/dev/disk/by-id/ata-VBOX_HARDDISK_VBb598f427-91b62771      /mnt/iso      ext4     defaults     0    0\n</code></pre></p> </li> <li> <p>On red\u00e9marre pour v\u00e9rifier que la configuration est bien effective !</p> </li> <li> <p>Si la cl\u00e9 est bien mont\u00e9e au red\u00e9marrage, on peut passer \u00e0 la configuration du stockage sur Proxmox :</p> </li> </ul> Configuration du stockage des ISO sur la cl\u00e9 USB"},{"location":"post-install/system/ssh/","title":"Post-Installation - SSH","text":"<p>Coming next</p>"},{"location":"post-install/system/users/","title":"Post-Installation - Utilisateur(s)","text":""},{"location":"post-install/system/users/#creer-un-utilisateur-standard","title":"Cr\u00e9er un utilisateur standard","text":"<p><code>useradd</code> est un utilitaire de ligne de commande qui peut \u00eatre utilis\u00e9 pour cr\u00e9er de nouveaux utilisateurs sur les syst\u00e8mes Linux et Unix.</p> <pre><code>useradd [OPTIONS] &lt;username&gt;\n</code></pre> <p>Sur la plupart des distributions Linux, lors de la cr\u00e9ation d'un nouveau compte utilisateur avec useradd, le r\u00e9pertoire personnel de l'utilisateur n'est pas cr\u00e9\u00e9. Il faut utiliser l'option <code>-m</code> ou  <code>--create-home</code> pour cr\u00e9er le r\u00e9pertoire de base de l'utilisateur sous <code>/home/&lt;username&gt;</code>.</p> <p>Cette commande cr\u00e9e le r\u00e9pertoire personnel du nouvel utilisateur et copie les fichiers du r\u00e9pertoire /etc/skel vers le r\u00e9pertoire personnel de l'utilisateur. Si vous listez les fichiers dans le r\u00e9pertoire <code>/home/&lt;username&gt;</code>, vous verrez les fichiers d'initialisation via :</p> <pre><code>ls -la /home/&lt;username&gt;/\n</code></pre> <p>Lorsqu'un nouvel utilisateur est cr\u00e9\u00e9, son shell de connexion est d\u00e9fini sur celui sp\u00e9cifi\u00e9 dans le fichier <code>/etc/default/useradd</code>. Dans certaines distributions, le shell par d\u00e9faut est d\u00e9fini sur <code>/bin/sh</code>, tandis que dans d'autres, il est d\u00e9fini sur <code>/bin/bash</code>.</p> <p>L'option <code>-s</code> ou <code>--shell</code> vous permet de sp\u00e9cifier le shell de connexion du nouvel utilisateur.</p> <p>Voici un exemple montrant comment cr\u00e9er un nouvel utilisateur nomm\u00e9 john avec <code>/usr/bin/zsh</code> comme type de shell de connexion :</p> <p>Cr\u00e9ons notre utilisateur :</p> <pre><code>useradd -m -s /bin/bash john\n</code></pre> <p>L'utilisateur a la possibilit\u00e9 d'\u00e9crire, de modifier et de supprimer des fichiers et des r\u00e9pertoires dans le r\u00e9pertoire personnel.</p>"},{"location":"post-install/system/users/#mot-de-passe-passwd","title":"Mot de passe : passwd","text":"<p>Assignons maintenant un mot de passe \u00e0 cet utilisateur :</p> <pre><code>passwd &lt;username&gt;\n</code></pre> <p>Tapez le mot de passe 2 fois et valider.</p>"},{"location":"post-install/system/wol/","title":"Activer Wake On LAN sur Debian","text":""},{"location":"post-install/system/wol/#installation-dethtool","title":"Installation d'<code>ethtool</code>","text":"<pre><code>root@morpheus:~# apt install ethtool\n</code></pre>"},{"location":"post-install/system/wol/#verification-de-linterface","title":"V\u00e9rification de l'interface","text":"<p><pre><code>root@morpheus:~# ip a\n</code></pre> Ou encore : <pre><code>root@morpheus:~# vi /etc/network/interface\n</code></pre></p>"},{"location":"post-install/system/wol/#selectionnez-linterface-que-vous-souhaitez-utiliser","title":"S\u00e9lectionnez l'interface que vous souhaitez utiliser","text":"<p>Par example : <pre><code>root@morpheus:~# enp2s0\n</code></pre></p>"},{"location":"post-install/system/wol/#activer-le-demarragereveil-sur-lan-temporairement","title":"Activer le d\u00e9marrage/r\u00e9veil sur LAN temporairement","text":"<pre><code>root@morpheus:~# ethtool --change enp2s0 wol g\n</code></pre>"},{"location":"post-install/system/wol/#verifiez-letat-wol-de-linterface-avec-la-commande-suivante","title":"V\u00e9rifiez l'\u00e9tat WOL de l'interface avec la commande suivante","text":"<pre><code>root@morpheus:~# ethtool enp2s0\n</code></pre>"},{"location":"post-install/system/wol/#retrouvez-la-section-ci-dessous-wake-on-g","title":"Retrouvez la section ci-dessous <code>Wake-on: g</code>","text":"<pre><code>root@morpheus:~# ethtool enp2s0 \nSettings for enp2s0:\n        Supported ports: [ TP    MII ]\n        Supported link modes:   10baseT/Half 10baseT/Full\n                                100baseT/Half 100baseT/Full\n                                1000baseT/Full\n                                2500baseT/Full\n        Supported pause frame use: Symmetric Receive-only\n        Supports auto-negotiation: Yes\n        Supported FEC modes: Not reported\n        Advertised link modes:  10baseT/Half 10baseT/Full\n                                100baseT/Half 100baseT/Full\n                                1000baseT/Full\n                                2500baseT/Full\n        Advertised pause frame use: Symmetric Receive-only\n        Advertised auto-negotiation: Yes\n        Advertised FEC modes: Not reported\n        Link partner advertised link modes:  10baseT/Half 10baseT/Full\n                                             100baseT/Half 100baseT/Full\n                                             1000baseT/Half 1000baseT/Full\n        Link partner advertised pause frame use: Symmetric Receive-only\n        Link partner advertised auto-negotiation: Yes\n        Link partner advertised FEC modes: Not reported\n        Speed: 1000Mb/s\n        Duplex: Full\n        Auto-negotiation: on\n        master-slave cfg: preferred slave\n        master-slave status: master\n        Port: Twisted Pair\n        PHYAD: 0\n        Transceiver: external\n        MDI-X: Unknown\n        Supports Wake-on: pumbg\n        Wake-on: g\n        Link detected: yes\n</code></pre>"},{"location":"post-install/system/wol/#rendre-le-reveil-sur-le-reseau-local-permanent","title":"Rendre le r\u00e9veil sur le r\u00e9seau local permanent","text":""},{"location":"post-install/system/wol/#trouver-le-repertoire-ethtool","title":"Trouver le r\u00e9pertoire <code>ethtool</code>","text":"<pre><code>root@morpheus:~# which ethtool\n</code></pre> <p>Sur Proxmox : <code>/usr/sbin/ethtool</code></p>"},{"location":"post-install/system/wol/#creez-le-fichier-wolservice-dans-etcsystemdsystem-avec-le-contenu-suivant","title":"Cr\u00e9ez le fichier wol.service dans /etc/systemd/system/ avec le contenu suivant","text":"<pre><code>root@morpheus:~# vi /etc/systemd/system/wol.service\n[Unit]\nDescription=Enable Wake On Lan\n\n[Service]\nType=oneshot\nExecStart = /usr/sbin/ethtool --change enp2s0 wol g\n\n[Install]\nWantedBy=basic.target\n</code></pre>"},{"location":"post-install/system/wol/#activer-le-service","title":"Activer le service","text":"<pre><code>root@morpheus:~# systemctl daemon-reload\nroot@morpheus:~# systemctl enable wol.service\n</code></pre>"},{"location":"services/docker/","title":"Index Docker","text":""},{"location":"services/docker/frontend-stack/","title":"LXC - Frontend","text":""},{"location":"services/docker/frontend-stack/#creation-dun-conteneur-lxc-via-proxmox-ve-helper-scripts","title":"Cr\u00e9ation d'un conteneur LXC via Proxmox VE Helper-Scripts","text":"<p>https://tteck.github.io/Proxmox/</p> <p>Sur Proxmox :</p> <pre><code>root@morpheus:~# bash -c \"$(wget -qLO - https://github.com/tteck/Proxmox/raw/main/ct/docker.sh)\"\n</code></pre>"},{"location":"services/docker/frontend-stack/#configuration-du-conteneur-lxc","title":"Configuration du conteneur LXC","text":"<p>...</p>"},{"location":"services/docker/frontend-stack/#dataset-zfs-point-de-montage","title":"Dataset ZFS &amp; Point de montage","text":""},{"location":"services/docker/frontend-stack/#creation-de-lensemble-de-donnees-dataset-sur-le-pool-zfs-rpool","title":"Cr\u00e9ation de l'ensemble de donn\u00e9es (dataset) sur le pool ZFS <code>rpool</code>","text":"<p>Dataset ZFS</p> <p>Les datasets sont des points de contr\u00f4le, ils peuvent \u00eatre imbriqu\u00e9s et h\u00e9ritent des propri\u00e9t\u00e9s de leur parent (appel\u00e9 \u00ab stub \u00bb). On peut \u00e9galement les faire pointer vers un dossier sur le syst\u00e8me de fichier. C'est ce que l'on appelle les points de montage.</p> <p>Pour cr\u00e9er un dataset qui va contenir les donn\u00e9es de mes stacks <code>docker compose</code>, rien de plus facile : <pre><code>root@morpheus:~# zfs create rpool/docker\n</code></pre></p> <p>Avec un point de montage sur la machine h\u00f4te (Proxmox) : <pre><code>root@morpheus:~# ls -l /opt/\ntotal 0\nroot@morpheus:~# mkdir /opt/docker\nroot@morpheus:~# ls -l /opt/\ntotal 1\ndrwxr-xr-x 2 root root 2 Apr 25 16:15 docker\nroot@morpheus:~# zfs create rpool/docker -o mountpoint=/opt/docker\n</code></pre></p> <p>V\u00e9rifions que le dataset a bien \u00e9t\u00e9 cr\u00e9\u00e9 : <pre><code>root@morpheus:~# zfs list\nNAME                           USED  AVAIL  REFER  MOUNTPOINT\nrpool                         3.83G   895G   104K  /rpool\nrpool/ROOT                    2.81G   895G    96K  /rpool/ROOT\nrpool/ROOT/pve-1              2.81G   895G  2.81G  /\nrpool/data                     995M   895G    96K  /rpool/data\nrpool/data/subvol-200-disk-0   995M  3.03G   995M  /rpool/data/subvol-200-disk-0\nrpool/docker                     96K   892G    96K  /opt/docker\nrpool/pgdata                  12.7M   895G  12.1M  /var/lib/postgresql\nrpool/var-lib-vz               104K   895G   104K  /var/lib/vz\n</code></pre></p>"},{"location":"services/docker/frontend-stack/#definition-dun-quota","title":"D\u00e9finition d'un quota","text":"<pre><code>root@morpheus:~# zfs set quota=20G rpool/docker\n\nroot@morpheus:~# zfs get quota rpool/docker\nNAME                  PROPERTY  VALUE  SOURCE\nrpool/docker  quota     20G    local\n</code></pre>"},{"location":"services/docker/frontend-stack/#desactiviation-atime-et-relatime","title":"D\u00e9sactiviation <code>atime</code> et <code>relatime</code>","text":"<pre><code>root@morpheus:~# zfs set atime=off rpool/docker\nroot@morpheus:~# zfs set relatime=off rpool/docker\n\nroot@morpheus:~# zfs get quota rpool/docker\nNAME                  PROPERTY  VALUE  SOURCE\nrpool/docker  quota     20G    local\n</code></pre> <p>Ensemble des options : <pre><code>root@morpheus:~# zfs get all rpool/docker\nNAME                  PROPERTY              VALUE                  SOURCE\nrpool/docker  type                  filesystem             -\nrpool/docker  creation              Thu Apr 25 16:16 2024  -\nrpool/docker  used                  96K                    -\nrpool/docker  available             20.0G                  -\nrpool/docker  referenced            96K                    -\nrpool/docker  compressratio         1.00x                  -\nrpool/docker  mounted               yes                    -\nrpool/docker  quota                 20G                    local\nrpool/docker  reservation           none                   default\nrpool/docker  recordsize            128K                   default\nrpool/docker  mountpoint            /opt/docker            local\nrpool/docker  sharenfs              off                    default\nrpool/docker  checksum              on                     default\nrpool/docker  compression           lz4                    inherited from rpool\nrpool/docker  atime                 on                     inherited from rpool\nrpool/docker  devices               on                     default\nrpool/docker  exec                  on                     default\nrpool/docker  setuid                on                     default\nrpool/docker  readonly              off                    default\nrpool/docker  zoned                 off                    default\nrpool/docker  snapdir               hidden                 default\nrpool/docker  aclmode               discard                default\nrpool/docker  aclinherit            restricted             default\nrpool/docker  createtxg             455656                 -\nrpool/docker  canmount              on                     default\nrpool/docker  xattr                 on                     default\nrpool/docker  copies                1                      default\nrpool/docker  version               5                      -\nrpool/docker  utf8only              off                    -\nrpool/docker  normalization         none                   -\nrpool/docker  casesensitivity       sensitive              -\nrpool/docker  vscan                 off                    default\nrpool/docker  nbmand                off                    default\nrpool/docker  sharesmb              off                    default\nrpool/docker  refquota              none                   default\nrpool/docker  refreservation        none                   default\nrpool/docker  guid                  6310504030969019186    -\nrpool/docker  primarycache          all                    default\nrpool/docker  secondarycache        all                    default\nrpool/docker  usedbysnapshots       0B                     -\nrpool/docker  usedbydataset         96K                    -\nrpool/docker  usedbychildren        0B                     -\nrpool/docker  usedbyrefreservation  0B                     -\nrpool/docker  logbias               latency                default\nrpool/docker  objsetid              1451                   -\nrpool/docker  dedup                 off                    default\nrpool/docker  mlslabel              none                   default\nrpool/docker  sync                  standard               inherited from rpool\nrpool/docker  dnodesize             legacy                 default\nrpool/docker  refcompressratio      1.00x                  -\nrpool/docker  written               96K                    -\nrpool/docker  logicalused           42K                    -\nrpool/docker  logicalreferenced     42K                    -\nrpool/docker  volmode               default                default\nrpool/docker  filesystem_limit      none                   default\nrpool/docker  snapshot_limit        none                   default\nrpool/docker  filesystem_count      none                   default\nrpool/docker  snapshot_count        none                   default\nrpool/docker  snapdev               hidden                 default\nrpool/docker  acltype               off                    default\nrpool/docker  context               none                   default\nrpool/docker  fscontext             none                   default\nrpool/docker  defcontext            none                   default\nrpool/docker  rootcontext           none                   default\nrpool/docker  relatime              on                     inherited from rpool\nrpool/docker  redundant_metadata    all                    default\nrpool/docker  overlay               on                     default\nrpool/docker  encryption            off                    default\nrpool/docker  keylocation           none                   default\nrpool/docker  keyformat             none                   default\nrpool/docker  pbkdf2iters           0                      default\nrpool/docker  special_small_blocks  0                      default\n</code></pre></p>"},{"location":"services/docker/frontend-stack/#creation-dun-dataset-frontend-stack-qui-va-herite-des-options-du-dataset-rpooldocker","title":"Cr\u00e9ation d'un dataset <code>frontend-stack</code> qui va h\u00e9rit\u00e9 des options du dataset <code>rpool/docker</code>","text":"<pre><code>root@morpheus:~# mkdir /opt/docker/frontend-stack\nroot@morpheus:~# zfs create rpool/docker/frontend-stack -o mountpoint=/opt/docker/frontend-stack\n</code></pre>"},{"location":"services/docker/frontend-stack/#partage-de-dossier-entre-la-machine-hote-et-le-conteneur","title":"Partage de dossier entre la machine h\u00f4te et le conteneur","text":"<p>Ajout du point de montage sur le conteneur LXC : <pre><code>root@morpheus:~# pct set 200 -mp0 /opt/docker/frontend-stack,mp=/opt/docker/frontend-stack\n</code></pre></p>"},{"location":"services/docker/frontend-stack/#gestion-des-droits-entre-proxmox-et-le-container-lxc","title":"Gestion des droits entre Proxmox et le container LXC","text":"<p>Gestion des droits entre l'host Proxmox et le container LXC sur lequel les donn\u00e9es vont \u00eatre mont\u00e9es</p> <p>Sur la machine h\u00f4te (Proxmox) pour l'utilisateur <code>root</code> : <pre><code>root@morpheus:~# chown -Rf 100000:100000 /opt/docker/frontend-stack\n</code></pre></p>"},{"location":"services/lxc/","title":"Virtual Machine (VM) et Linux Containers (LXC)","text":"<p>L'auto-h\u00e9bergement est devenue un passe-temps ! J'aime d\u00e9couvrir de nouveaux services que je pourrai \u00e9ventuellement mettre en place sur mon NAS et pour le moment, tous mes services tournent sur des conteneurs LXC depuis Proxmox.</p> Ensemble des machines d\u00e9ploy\u00e9es sur mon cluster Proxmox <p>Voici \u00e0 quoi ressemble mon architecture :</p> <pre><code>flowchart LR\n    proxmox@{ img: \"/assets/images/logo/proxmox.svg\", label: \"\", pos: \"t\", w: 100, h: 50, constraint: \"on\" }\n    style proxmox color:none,fill:none,stroke:none,stroke-width:0px\n\n    subgraph **Cluster Proxmox**\n      morpheus(\"**Morpheus**&lt;br/&gt;PVE\")\n      style morpheus color:#ffffff,fill:none,stroke:#333,stroke-width:2px\n      neo(\"**Neo**&lt;br/&gt;PVE + PBS\")\n      neo-pve(\"**Neo**&lt;br/&gt;PVE:8006\")\n      neo-pbs(\"**Neo**&lt;br/&gt;PBS:8007\")\n      style neo color:#ffffff,fill:none,stroke:#333,stroke-width:2px\n    end\n\n    subgraph **Conteneurs LXC**\n        frontend{\"__Frontend__&lt;br/&gt;M\u00e9moire : __1GO__&lt;br/&gt;Swap : __1GO__&lt;br/&gt;Cores : __2__&lt;br/&gt;Disque : __16GO__\"}\n        elephant{\"__Elephant__&lt;br/&gt;M\u00e9moire : __16GO__&lt;br/&gt;Swap : __1GO__&lt;br/&gt;Cores : __4__&lt;br/&gt;Disque : __128GO__\"}\n        jellyfin{\"__Jellyfin__&lt;br/&gt;M\u00e9moire : __8GO__&lt;br/&gt;Swap : __4GO__&lt;br/&gt;Cores : __4__&lt;br/&gt;Disque : __32GO__\"}\n        mediaserver{\"__Mediaserver__&lt;br/&gt;M\u00e9moire : __1GO__&lt;br/&gt;Swap : __1GO__&lt;br/&gt;Cores : __2__&lt;br/&gt;Disque : __16GO__\"}\n        nextcloud{\"__Nextcloud__&lt;br/&gt;M\u00e9moire : __4GO__&lt;br/&gt;Swap : __4GO__&lt;br/&gt;Cores : __2__&lt;br/&gt;Disque : __16GO__\"}\n        immich{\"__Immich__&lt;br/&gt;M\u00e9moire : __8GO__&lt;br/&gt;Swap : __4GO__&lt;br/&gt;Cores : __4__&lt;br/&gt;Disque : __16GO__\"}\n        webapps{\"__Webapps__&lt;br/&gt;M\u00e9moire : __1GO__&lt;br/&gt;Swap : __512MO__&lt;br/&gt;Cores : __2__&lt;br/&gt;Disque : __16GO__\"}\n        sysadmin{\"__Sysadmin__&lt;br/&gt;M\u00e9moire : __1GO__&lt;br/&gt;Swap : __512MO__&lt;br/&gt;Cores : __2__&lt;br/&gt;Disque : __16GO__\"}\n        communication{\"__Communication__&lt;br/&gt;M\u00e9moire : __512MO__&lt;br/&gt;Swap : __512MO__&lt;br/&gt;Cores : __2__&lt;br/&gt;Disque : __8GO__\"}\n    end\n\n    subgraph **Conteneurs LXC**\n        smarthome{\"__Smarthome__&lt;br/&gt;M\u00e9moire : __1GO__&lt;br/&gt;Swap : __1GO__&lt;br/&gt;Cores : __2__&lt;br/&gt;Disque : __16GO__\"}\n    end\n\n    subgraph **Services**\n        docker-frontend-stack[&lt;img src=\"/assets/images/logo/docker-logo-blue.png\" width=\"200\" /&gt;***Portainer***&lt;br/&gt;***Traefik***&lt;br/&gt;***Authelia***&lt;br/&gt;***Fail2ban***&lt;br/&gt;***Headscale***&lt;br/&gt;***Tailscale***]\n        style docker-frontend-stack color:none,fill:none,stroke:none,stroke-width:0px\n\n        elephant-stack[***PostgreSQL 16***&lt;br/&gt;***PostGIS 3.4.2***]\n        style elephant-stack color:none,fill:none,stroke:none,stroke-width:0px\n\n        docker-jellyfin-stack[&lt;img src=\"/assets/images/logo/docker-logo-blue.png\" width=\"200\" /&gt;***Jellyfin***&lt;br/&gt;***TinyMediaManager***]\n        style docker-jellyfin-stack color:none,fill:none,stroke:none,stroke-width:0px\n\n        docker-mediaserver-stack[&lt;img src=\"/assets/images/logo/docker-logo-blue.png\" width=\"200\" /&gt;***Navidrome***&lt;br/&gt;***Bonob***&lt;br/&gt;***Calibre Web***]\n        style docker-mediaserver-stack color:none,fill:none,stroke:none,stroke-width:0px\n\n        docker-nextcloud-stack[&lt;img src=\"/assets/images/logo/docker-logo-blue.png\" width=\"200\" /&gt;***Nextcloud***&lt;br/&gt;***Onlyoffice***]\n        style docker-nextcloud-stack color:none,fill:none,stroke:none,stroke-width:0px\n\n        docker-immich-stack[&lt;img src=\"/assets/images/logo/docker-logo-blue.png\" width=\"200\" /&gt;***Immich***]\n        style docker-immich-stack color:none,fill:none,stroke:none,stroke-width:0px\n\n        docker-webapps-stack[&lt;img src=\"/assets/images/logo/docker-logo-blue.png\" width=\"200\" /&gt;***Homepage***&lt;br/&gt;***Filebrowser***&lt;br/&gt;***Vaultwarden***&lt;br/&gt;***Jellystat***]\n        style docker-webapps-stack color:none,fill:none,stroke:none,stroke-width:0px\n\n        docker-sysadmin-stack[&lt;img src=\"/assets/images/logo/docker-logo-blue.png\" width=\"200\" /&gt;***Healthchecks***&lt;br/&gt;***Uptime-Kuma***&lt;br/&gt;***Dozzle***]\n        style docker-sysadmin-stack color:none,fill:none,stroke:none,stroke-width:0px\n\n        docker-communication-stack[&lt;img src=\"/assets/images/logo/docker-logo-blue.png\" width=\"200\" /&gt;***NTFY***]\n        style docker-communication-stack color:none,fill:none,stroke:none,stroke-width:0px\n\n        docker-smarthome-stack[&lt;img src=\"/assets/images/logo/docker-logo-blue.png\" width=\"200\" /&gt;***Home-Assistant***&lt;br/&gt;***Zigbee2mQTT***&lt;br/&gt;***Node-Red***&lt;br/&gt;***ESPHome***]\n        style docker-smarthome-stack color:none,fill:none,stroke:none,stroke-width:0px\n    end\n\n    proxmox --&gt; morpheus\n    proxmox --&gt; neo\n    neo --&gt; neo-pve\n    neo --&gt; neo-pbs\n    morpheus --&gt; frontend --&gt; docker-frontend-stack\n    morpheus --&gt; elephant --&gt; elephant-stack\n    morpheus --&gt; jellyfin --&gt; docker-jellyfin-stack\n    morpheus --&gt; mediaserver --&gt; docker-mediaserver-stack\n    morpheus --&gt; nextcloud --&gt; docker-nextcloud-stack\n    morpheus --&gt; immich --&gt; docker-immich-stack\n    morpheus --&gt; webapps --&gt; docker-webapps-stack\n    morpheus --&gt; sysadmin --&gt; docker-sysadmin-stack\n    morpheus --&gt; communication --&gt; docker-communication-stack\n    neo-pve --&gt; smarthome --&gt; docker-smarthome-stack\n\n    click frontend href \"/services/lxc/frontend\"\n    click docker-frontend-stack href \"/services/docker/frontend-stack\"</code></pre>"},{"location":"services/lxc/frontend/","title":"Frontend LXC","text":""},{"location":"tech-stack/data/","title":"02-03/ T\u00e9l\u00e9chargement des donn\u00e9es \"socle\"","text":"<p>Pour cr\u00e9er une carte topo, il nous faut des donn\u00e9es vectorielles. La donn\u00e9e de base qui va nous servir de socle \u00e0 la cr\u00e9ation de notre carte personnalis\u00e9e va \u00eatre la BD TOPO\u00ae de l'IGN. Cette donn\u00e9e \"socle\" sera compl\u00e9t\u00e9e par les donn\u00e9es d'OpenStreetMap via GeoFabrik ainsi que les donn\u00e9es de sentier de randonn\u00e9es glann\u00e9es ici et l\u00e0, car cette donn\u00e9e n'est pas en Open-Data.</p> <p>N'oublions pas les donn\u00e9es \"Raster\" d'\u00e9l\u00e9vation que nous t\u00e9l\u00e9chargerons sur ce site http://dwtkns.com/srtm30m/ et apr\u00e8s s\u2019\u00eatre inscrit gratuitement sur le site de la NASA Earth Observation Data d\u2019o\u00f9 provient la donn\u00e9e.</p>"},{"location":"tech-stack/data/#vecteurs","title":"Vecteurs","text":""},{"location":"tech-stack/data/#ign-bd-topo","title":"IGN BD TOPO\u00ae","text":"<p>Afin de r\u00e9aliser notre carte Garmin Topo, nous utiliserons comme donn\u00e9es de base, la BD TOPO\u00ae de l'IGN qui est d\u00e9sormais en t\u00e9l\u00e9chargement libre depuis le 1er janvier 2021.</p> <p>Ce qui est tr\u00e8s int\u00e9ressant avec ce jeu de donn\u00e9es, c\u2019est qu\u2019on peut la t\u00e9l\u00e9charger sur des \u00e9chelles de territoire assez vari\u00e9es, du d\u00e9partement en passant par la r\u00e9gion ou encore sur l\u2019ensemble du territoire fran\u00e7ais.</p> <p> </p> IGN BD TOPO\u00ae \u2014 La mod\u00e9lisation 2D et 3D du territoire et de ses infrastructures sur l\u2019ensemble du territoire fran\u00e7ais <p>La BD TOPO\u00ae est une description vectorielle 3D (structur\u00e9e en objets) des \u00e9l\u00e9ments du territoire et de ses infrastructures, de pr\u00e9cision m\u00e9trique, exploitable \u00e0 des \u00e9chelles allant du 1 : 2 000 au 1 : 50 000.</p> <p>Elle couvre de mani\u00e8re coh\u00e9rente l\u2019ensemble des entit\u00e9s g\u00e9ographiques et administratives du territoire national fran\u00e7ais.</p> <p>Elle permet la visualisation, le positionnement, la simulation au service de l\u2019analyse et de la gestion op\u00e9rationnelle du territoire. La description des objets g\u00e9ographiques en 3D permet de repr\u00e9senter de fa\u00e7on r\u00e9aliste les analyses spatiales utiles aux processus de d\u00e9cision dans le cadre d\u2019\u00e9tudes diverses.</p> <p>Notons que la majorit\u00e9 de ces objets sont num\u00e9ris\u00e9s avec la dimension Z (en 3D). Elle ne nous sera pas n\u00e9cessaire et nous la supprimerons dans la r\u00e9alisation de la carte pour n\u2019avoir que des objets vectoriels en 2D .</p> <p>Depuis 2019, une nouvelle \u00e9dition (mise \u00e0 jour) est publi\u00e9e chaque trimestre, nous permettant de faire \u00e9voluer notre carte Garmin personnalis\u00e9e assez r\u00e9guli\u00e8rement.</p> <p>Les objets de la BD TOPO\u00ae sont regroup\u00e9s par th\u00e8mes guid\u00e9s par la mod\u00e9lisation INSPIRE1 :</p> <ul> <li>Administratif (limites et unit\u00e9s administratives)</li> <li>Adresses (adresses postales),</li> <li>B\u00e2ti (constructions),</li> <li>Hydrographie (\u00e9l\u00e9ments ayant trait \u00e0 l\u2019eau),</li> <li>Lieux nomm\u00e9s (lieu ou lieu-dit poss\u00e9dant un toponyme et d\u00e9crivant un espace naturel ou un lieu habit\u00e9),</li> <li>Occupation du sol (v\u00e9g\u00e9tation, estran, haie),</li> <li>Services et activit\u00e9s (services publics, stockage et transport des sources d\u2019\u00e9nergie, lieux et sites industriels),</li> <li>Transport (infrastructures du r\u00e9seau routier, ferr\u00e9 ou a\u00e9rien, itin\u00e9raires),</li> <li>Zones r\u00e9glement\u00e9es (la plupart des zonages faisant l\u2019objet de r\u00e9glementations sp\u00e9cifiques).</li> </ul> <p>Nous n\u2019utiliserons pas l\u2019ensemble des donn\u00e9es pr\u00e9sentes dans ce jeu de donn\u00e9es. Il vous est aussi possible d\u2019enrichir la carte avec d\u2019autres base de donn\u00e9es g\u00e9ographiques une fois que vous avez compris le processus de cr\u00e9ation d\u2019une carte Garmin personnalis\u00e9e.</p>"},{"location":"tech-stack/data/#sentier-de-randonnees-gr","title":"Sentier de randonn\u00e9es - GR","text":""},{"location":"tech-stack/data/#openstreetmap","title":"OpenStreetMap","text":""},{"location":"tech-stack/data/#raster","title":"Raster","text":""},{"location":"tech-stack/data/#30-meter-srtm","title":"30-Meter SRTM","text":""},{"location":"tech-stack/folder-tree/","title":"02-02/ Arborescence des dossiers","text":"<p>Ici, c\u2019est \u00e0 vous d\u2019organiser la fa\u00e7on dont vous allez structurer vos donn\u00e9es. Je vous conseille d\u2019\u00eatre assez ordonn\u00e9 car vous allez vite vous perdre avec la multitude de fichiers que vous allez manipuler avec ce tutoriel.</p> <p>Voici mon arborescence pour vous donner une id\u00e9e :</p> <p> </p> Arborescence des dossiers/fichiers <p>\u00c9videmment, votre structure de dossiers ne doit pas n\u00e9cessairement \u00eatre exactement comme celle-ci.</p> <p>Avec cette arborescence de dossiers, on visualise d\u00e9j\u00e0 le processus de cr\u00e9ation de la carte Garmin. Je d\u00e9taillerai plus tard ce processus afin de bien comprendre comment on cr\u00e9e ce type de carte Topo.</p>"},{"location":"tech-stack/hardware/","title":"Mat\u00e9riel","text":"D\u00e9cembre 2023Avant","tags":["Hardware","Composants"]},{"location":"tech-stack/hardware/#decembre-2023","title":"D\u00e9cembre 2023","text":"","tags":["Hardware","Composants"]},{"location":"tech-stack/hardware/#composants","title":"Composants","text":"<p>Voici un aper\u00e7u du mat\u00e9riel mise en oeuvre :</p> Composant Mod\u00e8le Pour quelle raison ? Bo\u00eetier Fractal Design Node 304 Noir  Recommandation via GuiPom Carte-m\u00e8re ASRock H670M-ITX/ax 4 SATA3 - 1 Hyper M.2 (PCIe Gen4 x4) - 1 Hyper M.2 (PCIe Gen4 x4 &amp; SATA3) CPU Intel Core i3-13100 (3.4 GHz / 4.5 GHz)  iGPU avec transcodage Quicksync int\u00e9gr\u00e9 M\u00e9moire Crucial Pro 64GB Kit (2x32GB) DDR4-3200 - Non ECC Suffisant pour ex\u00e9cuter l\u2019int\u00e9gralit\u00e9 de ma pile de production SSD boot 2 * Crucial P5 Plus 1To NVMe SSD Disque SSD syst\u00e8me Alimentation Be Quiet SYSTEM POWER 9 400W Disques dur Un m\u00e9lange de disques de 1 \u00e0 18 To","tags":["Hardware","Composants"]},{"location":"tech-stack/hardware/#logiciels-conteneurs","title":"Logiciels / Conteneurs","text":"Type Produit / Version Pour quelle raison ? OS Proxmox 8.1 Il y a d'autres produits opensource plus performants que Proxmox pour g\u00e9rer ses VMs ? Parit\u00e9 SnapRAID Stocke les informations de parit\u00e9 de vos donn\u00e9es et r\u00e9cup\u00e8re jusqu'\u00e0 six pannes de disque Gestion des HDDs mergerfs Syst\u00e8me de fichiers destin\u00e9 \u00e0 simplifier le stockage et la gestion des fichiers sur de nombreux HDD Conteneurs docker Existe-t-il une autre fa\u00e7on d\u2019ex\u00e9cuter un logiciel ? Conteneur Usage Lien de contenu pertinent Traefik Reverse proxy","tags":["Hardware","Composants"]},{"location":"tech-stack/hardware/#avant","title":"Avant","text":"","tags":["Hardware","Composants"]},{"location":"tech-stack/hardware/#composants_1","title":"Composants","text":"Composant Mod\u00e8le Pour quelle raison ? Intel NUC Intel\u00ae NUC NUC7i3BNH Faible consommation \u00e9lectrique - Facile \u00e0 trouver d'occasion Raspberri PI 3 Raspberry Pi 3 Model B Ordinateur monocarte avec connectivit\u00e9 LAN sans fil et Bluetooth","tags":["Hardware","Composants"]},{"location":"tech-stack/hardware/#logiciels-conteneurs_1","title":"Logiciels / Conteneurs","text":"Type Produit / Version Pour quelle raison ? OS Debian 11 Parce que j'aime bien Debian Parit\u00e9 - Gestion des HDDs - Conteneurs docker Existe-t-il une autre fa\u00e7on d\u2019ex\u00e9cuter un logiciel ? Conteneur Usage Lien de contenu pertinent Swag Reverse proxy","tags":["Hardware","Composants"]},{"location":"tech-stack/processus/","title":"M\u00e9thodologie","text":"<p>On va donc retrouver sous le capot :</p>"},{"location":"tech-stack/processus/#proxmox-virtual-environment","title":"Proxmox Virtual Environment","text":"<p>Installation en baremetal, Proxmox Virtual Environment est une plate-forme compl\u00e8te de gestion de serveurs open source pour la virtualisation d'entreprise. Il int\u00e8gre \u00e9troitement l'hyperviseur KVM et les conteneurs Linux (LXC), la fonctionnalit\u00e9 de stockage et de r\u00e9seau d\u00e9finie par logiciel, sur une plate-forme unique. Avec une interface utilisateur bas\u00e9e sur le web, vous pouvez g\u00e9rer les machines virtuelles et les conteneurs, la haute disponibilit\u00e9 pour les clusters ou les outils de reprise apr\u00e8s sinistre int\u00e9gr\u00e9s avec facilit\u00e9. Par cons\u00e9quent, il y a une \u00e9norme marge de man\u0153uvre pour l'\u00e9volutivit\u00e9 du serveur.</p> <p>Proxmox est le bon choix pour vous si :</p> <ol> <li>Vous aimez une distribution Linux stable qui est Debian,</li> <li>Vous voulez faire fonctionner des machines virtuelles et des conteneurs LXC,</li> <li>Vous voulez utiliser la technologie ZFS,</li> <li>Vous souhaitez regrouper plusieurs serveurs,</li> <li>Vous souhaitez aller plus loin avec Proxmox Backup Server.</li> </ol>"},{"location":"tech-stack/processus/#donnees-et-stockage","title":"Donn\u00e9es et stockage","text":""},{"location":"tech-stack/processus/#mergerfs","title":"MergerFS","text":"<p>MergerFS est un syst\u00e8me de fichiers d'union tr\u00e8s puissant. Il sera utilis\u00e9 dans ce projet pour \u00ab fusionner \u00bb les disques ensemble pour cr\u00e9er un point de montage unifi\u00e9 de stockage.</p> <p>Voici un petit sch\u00e9ma de principe :</p> <pre><code>flowchart TD\n    storage[\"/mnt/storage\"]\n    mergerfs-disks[\"MergerFS&lt;br/&gt;/mnt/disk*\"]\n    style mergerfs-disks color:#ffffff,fill:#0000ff,stroke:#333,stroke-width:2px\n\n    subgraph Disques durs\n        disk1{\"/mnt/disk1&lt;br/&gt;ext4 18TB\"}\n        disk2{\"/mnt/disk2&lt;br/&gt;ext4 16TB\"}\n        disk3{\"/mnt/disk3&lt;br/&gt;ext4 16TB\"}\n    end\n\n    storage --&gt; mergerfs-disks\n    mergerfs-disks --&gt; disk1\n    mergerfs-disks --&gt; disk2\n    mergerfs-disks --&gt; disk3</code></pre> <p>Souligons que MergerFS utilise des politiques de stockage pour d\u00e9finir comment les donn\u00e9es sont copi\u00e9es/hi\u00e9rarchis\u00e9es sur les diff\u00e9rents disques qui composent le pool unifi\u00e9, et c'est le choix d'une de ces politiques qui va nous permettent de configurer notre NAS. \u00c0 savoir qu'une politique est l'algorithme utilis\u00e9 pour choisir une ou plusieurs branches (comprendre disques) sur lesquelles une fonction doit travailler ou, de mani\u00e8re g\u00e9n\u00e9rale, comment la fonction se comporte.</p> <p>Il en existe une bonne liste mais je m'attarderais sur deux qui ont retenu mon attention, <code>lfs</code> et <code>epmfs</code> :</p> <ul> <li><code>lfs</code> pour <code>Least Free Space</code> - choix de la branche avec le moins d\u2019espace libre disponible : vise \u00e0 \u00e9quilibrer l'espace libre sur tous les disques. MergerFS \u00e9crit toujours de nouvelles donn\u00e9es sur le disque avec l'espace le moins libre disponible.</li> </ul> <p>Note</p> <p>Bien que cela utilise uniform\u00e9ment tous les disques, cela repr\u00e9sente des inconv\u00e9nients importants pour des cas d'utilisation sp\u00e9cifiques. Pour les collections de m\u00e9dias, o\u00f9 les fichiers connexes (comme les \u00e9pisodes d'une \u00e9mission de t\u00e9l\u00e9vision) sont souvent consult\u00e9s ensemble, la politique  <code>lfs</code> peut diffuser ces fichiers \u00e0 travers plusieurs disques. Par exemple, si vous avez quatre saisons d'\u00e9mission t\u00e9l\u00e9vis\u00e9e, les \u00e9pisodes de chaque saison pourraient se retrouver sur un disque diff\u00e9rent.</p> <p>Cette approche peut conduire \u00e0 :</p> <ul> <li>une r\u00e9cup\u00e9ration inefficace : l'acc\u00e8s \u00e0 une saison compl\u00e8te pourrait n\u00e9cessiter la filature de plusieurs disques, plus de consommation d'\u00e9nergie, l'usure des disques,</li> <li>un cauchemare dans l'organisation des fichiers : l'\u00e9talement des fichiers connexes est lourd pour travailler sur les donn\u00e9es qui devraient \u00eatre ensemble,</li> <li>Si on perd un lecteur et de la parit\u00e9, il est plus facile de r\u00e9cup\u00e9rer une petite partie de donn\u00e9es similaires, contre des milliers de fichiers al\u00e9atoires.</li> </ul> <ul> <li><code>epmfs</code> pour <code>Existing Path, Most Free Space</code> - parmi toutes les branches sur lesquelles le chemin relatif existe, choisissez la branche avec le plus d'espace libre : il faut comprendre priorit\u00e9 au r\u00e9pertoire existant, si un r\u00e9pertoire existe d\u00e9j\u00e0 sur l'un des disques, de nouveaux fichiers destin\u00e9s \u00e0 ce r\u00e9pertoire y seront plac\u00e9s. Cela garantit que les fichiers connexes, comme les \u00e9pisodes de la m\u00eame saison t\u00e9l\u00e9vis\u00e9e, restent ensemble sur le m\u00eame disque tant qu'il y a de l'espace.</li> </ul> <p>Note</p> <p>Si le r\u00e9pertoire n'existe sur aucun disque (par exemple, lors de l'ajout d'une nouvelle \u00e9mission de t\u00e9l\u00e9vision ou d'une nouvelle saison), l'annuaire sera cr\u00e9\u00e9 sur le disque avec l'espace le plus important. Cela aide \u00e0 \u00e9quilibrer l'utilisation globale du stockage \u00e0 travers les disques.</p> <p>La politique <code>epmfs</code> combine le meilleur des deux options. Il maintient les fichiers connexes ensemble pour plus de clart\u00e9, tout en veillant \u00e0 ce que l'espace disque soit utilis\u00e9 efficacement, et c'est donc ce que je vais utiliser sur mon pool de donn\u00e9es MergerFS.</p>"},{"location":"tech-stack/software-tools/","title":"02-01/ Logiciels &amp; outils","text":"<p>\u00c9tant g\u00e9omaticien de m\u00e9tier, je b\u00e9n\u00e9ficie pour l\u2019occasion d\u2019une petite panoplie d\u2019outils soumis \u00e0 licences payantes. Je pense notamment \u00e0 Global Mapper et de FME. Ce seront mes 2 outils cl\u00e9s dans la pr\u00e9paration des donn\u00e9es cartographiques. Je vous rassure, il est tout \u00e0 fait possible d\u2019aller jusqu\u2019au bout de ce didacticiel avec des logiciels libres ou gratuits (\u00e9ventuellement avec quelques mises en garde) mais le chemin sera quand m\u00eame bien plus long &amp; compliqu\u00e9.</p> <p>Voici une liste de logiciels (non exhaustive) que nous pourrons utiliser dans la conception de notre carte :</p> <ul> <li>QGIS \u2014 programme SIG open source ; le meilleur logiciel SIG bureautique Open Source utilis\u00e9 pour manipuler des donn\u00e9es de mani\u00e8re graphique et/ou par ligne de commande (pr\u00e9f\u00e9rez la version de l\u2019installateur r\u00e9seau OSGeo4W),</li> <li>GPSMapEdit \u2014 logiciel shareware sp\u00e9cialement con\u00e7u pour fonctionner avec les cartes de type Garmin MP (la licence supprime simplement l\u2019\u00e9tiquette indiquant faite avec GPSMapEdit et ajoute quelques fonctionnalit\u00e9s d\u2019exportation suppl\u00e9mentaires que nous n\u2019utiliserons pas),</li> <li>FME \u2014 outil de traitement des donn\u00e9es con\u00e7u \u00e0 l\u2019origine pour manipuler des informations g\u00e9ographiques mais qui s\u2019est montr\u00e9 terriblement efficace pour traiter des donn\u00e9es de toutes natures avec une interface et une ergonomie sans \u00e9gal : Bases de donn\u00e9es, SIG, tableurs, images, XML, plans CAO, cloud, big data, nuages de points\u2026 FME est capable de lire et d\u2019\u00e9crire plus de 500 formats et propose des centaines d\u2019op\u00e9rateurs pour tous les besoins. ==Malheureusement, il ne g\u00e8re pas le format natif Garmin ou encore le format de code source utilis\u00e9 par le compilateur cGPSmapper ou Mkgmap qui est appel\u00e9 PFM (Polski Format Mappy \u2014 Format de carte polonais \u2014 .MP) ou \u201cFormat polonais\u201d. C\u2019est l\u2019outil Global Mapper qui va nous permettre de transformer nos fichiers ESRI Shapefile en fichier .MP.==</li> <li>Global Mapper \u2014 logiciel puissant pour \u00e9diter les donn\u00e9es ; plus rapide que les autres m\u00e9thodes. Facilite \u00e9galement l\u2019exportation vers le type *.mp par rapport \u00e0 QGIS,</li> <li>mkgmap \u2014 outil Java qui permet de g\u00e9n\u00e9rer une carte au format de fichier Garmin *.img afin qu\u2019elle puisse \u00eatre charg\u00e9e sur des appareils GPS compatibles,</li> <li>GMAPtool \u2014outil pour diviser et fusionner des cartes au format Garmin *.IMG,</li> <li>TYPViewer \u2014 un \u00e9diteur de fichier TYP pour GPS Garmin.</li> <li>GPSFDshp2mp \u2014 outil pour convertir les fichiers de formes en fichiers de texte polonais (MP) (facultatif pour les utilisateurs de Global Mapper),</li> <li>cgpsmapper \u2014 programme pour convertir les donn\u00e9es dans la carte Garmin finale (le site Web d\u2019origine n\u2019est plus disponible ; il s\u2019agit d\u2019un miroir fourni par GPSFileDepot),</li> <li>MapSetToolkit \u2014 permet de cr\u00e9er facilement les fichiers de pr\u00e9visualisation (gratuit).</li> </ul>"},{"location":"temp/zfs/","title":"Zfs","text":"<pre><code>---\ntitle : Sch\u00e9ma de principe ZFS\n---\nflowchart TD\n    storage[\"/mnt/storage\"]\n    mergerfs-disks[\"MergerFS&lt;br/&gt;/mnt/disk*\"]\n    style mergerfs-disks color:#ffffff,fill:#0000ff,stroke:#333,stroke-width:2px\n\n    subgraph Ensemble des disques\n        subgraph Disques durs\n            disk1{\"/mnt/disk1&lt;br/&gt;ext4 18TB\"}\n            disk2{\"/mnt/disk2&lt;br/&gt;ext4 16TB\"}\n            disk3{\"/mnt/disk3&lt;br/&gt;ext4 16TB\"}\n        end\n\n        subgraph \"/mnt/tank&lt;br/&gt;zfs-mirror 16TB x 2\"\n            zfsDisk1{\"/mnt/zfs/disk1&lt;br&gt;zfs 18TB\"}\n            zfsDisk2{\"/mnt/zfs/disk1&lt;br&gt;zfs 18TB\"}\n\n            zfs-mirror[\"/mnt/tank&lt;br/&gt;zfs-mirror 16TB x 2\"]\n            style mergerfs-disks color:#ffffff,fill:#0000ff,stroke:#333,stroke-width:2px\n        end\n    end    \n\n    storage --&gt; mergerfs-disks\n    mergerfs-disks --&gt; disk1\n    mergerfs-disks --&gt; disk2\n    mergerfs-disks --&gt; disk3\n    mergerfs-disks --&gt; zfsDisk1 ~~~ zfs-mirror\n    mergerfs-disks --&gt; zfsDisk2 ~~~ zfs-mirror</code></pre>"},{"location":"wiki/docker/","title":"Wiki - Docker","text":"<ul> <li> <p> DOCKER CLI : les lignes de commande</p> <p>Utilisez la ligne de commande Docker</p> <p> En savoir plus</p> </li> <li> <p> DOCKER NETWORK : Le r\u00e9seau</p> <p>Focus on your content and generate a responsive and searchable static site</p> <p> En savoir plus</p> </li> </ul>"},{"location":"wiki/docker/docker-cli/","title":"Docker CLI","text":"<p>Pour r\u00e9pertorier les commandes disponibles, ex\u00e9cutez <code>docker</code> sans param\u00e8tres ou ex\u00e9cutez <code>docker help</code> :</p> <p>Les commandes de base pour la CLI Docker.</p>"},{"location":"wiki/docker/docker-cli/#executer-des-conteneurs","title":"Ex\u00e9cuter des conteneurs","text":"COMMAND DESCRIPTION <code>docker run IMAGE</code> D\u00e9marrer un nouveau conteneur <code>docker run --name CONTAINER IMAGE</code> D\u00e9marrez un nouveau conteneur et d\u00e9finissez un nom <code>docker run -p HOSTPORT:CONTAINERPORT IMAGE</code> D\u00e9marrer un nouveau conteneur avec des ports mapp\u00e9s <code>docker run -P IMAGE</code> D\u00e9marrez un nouveau conteneur et mappez tous les ports"},{"location":"wiki/docker/docker-cli/#gestion-des-conteneurs","title":"Gestion des conteneurs","text":"COMMAND DESCRIPTION <code>docker create IMAGE</code> Cr\u00e9er un nouveau conteneur <code>docker start CONTAINER</code> D\u00e9marrer un conteneur <code>docker stop CONTAINER</code> Arr\u00eat gracieux d'un conteneur <code>docker kill CONTAINER</code> Tuer (SIGKILL) un conteneur <code>docker restart CONTAINER</code> Arr\u00eater et red\u00e9marrer gracieucesement un conteneur <code>docker pause CONTAINER</code> Suspendre un conteneur <code>docker unpause CONTAINER</code> Reprendre un conteneur <code>docker rm CONTAINER</code> D\u00e9truire un conteneur"},{"location":"wiki/docker/docker-cli/#gestion-des-conteneurs-en-vrac","title":"Gestion des conteneurs en vrac","text":"COMMAND DESCRIPTION <code>docker stop $(docker ps -q)</code> Pour arr\u00eater tous les conteneurs en cours d'ex\u00e9cution <code>docker stop $(docker ps -a -q)</code> Pour arr\u00eater tous les conteneurs arr\u00eat\u00e9s et en cours d'ex\u00e9cution <code>docker kill $(docker ps -q)</code> Pour tuer tous les conteneurs en cours d'ex\u00e9cution <code>docker kill $(docker ps -a -q)</code> Pour tuer tous les conteneurs arr\u00eat\u00e9s et en cours d'ex\u00e9cution <code>docker restart $(docker ps  -q)</code> Pour red\u00e9marrer tous les conteneurs en cours d'ex\u00e9cution <code>docker restart $(docker ps -a -q)</code> Pour red\u00e9marrer tous les conteneurs arr\u00eat\u00e9s et en cours d'ex\u00e9cution <code>docker rm $(docker ps  -q)</code> Pour d\u00e9truire tous les conteneurs en cours d'ex\u00e9cution <code>docker rm $(docker ps -a -q)</code> Pour d\u00e9truire tous les conteneurs arr\u00eat\u00e9s et en cours d'ex\u00e9cution <code>docker pause $(docker ps  -q)</code> Pour suspendre tous les conteneurs en cours d'ex\u00e9cution <code>docker pause $(docker ps -a -q)</code> Pour suspendre tous les conteneurs arr\u00eat\u00e9s et en cours d'ex\u00e9cution <code>docker start $(docker ps  -q)</code> Pour d\u00e9marrer tous les conteneurs en cours d'ex\u00e9cution <code>docker start $(docker ps -a -q)</code> Pour d\u00e9marrer tous les conteneurs arr\u00eat\u00e9s et en cours d'ex\u00e9cution <code>docker rm -vf $(docker ps -a -q)</code> Pour supprimer tous les conteneurs, y compris ses volumes, utilisez <code>docker rmi -f $(docker images -a -q)</code> Pour supprimer toutes les images <code>docker system prune</code> Pour supprimer toutes les images, conteneurs, caches et volumes en suspens et inutilis\u00e9s <code>docker system prune -a</code> Pour supprimer toutes les images utilis\u00e9es et inutilis\u00e9es <code>docker system prune --volumes</code> Pour supprimer tous les volumes Docker"},{"location":"wiki/docker/docker-cli/#inspecter-les-conteneurs","title":"Inspecter les conteneurs","text":"COMMAND DESCRIPTION <code>docker ps</code> R\u00e9pertorier les conteneurs en cours d'ex\u00e9cution <code>docker ps -a</code> R\u00e9pertorier tous les conteneurs, y compris ceux arr\u00eat\u00e9s <code>docker logs CONTAINER</code> Afficher une sortie de conteneur <code>docker logs -f CONTAINER</code> Suivre une sortie de conteneur <code>docker top CONTAINER</code> Lister les processus ex\u00e9cut\u00e9s dans un conteneur <code>docker diff</code> Montrer les diff\u00e9rences avec l'image (fichiers modifi\u00e9s) <code>docker inspect</code> Afficher les informations d'un conteneur (format\u00e9 json)"},{"location":"wiki/docker/docker-cli/#executer-des-commandes","title":"Ex\u00e9cuter des commandes","text":"COMMAND DESCRIPTION <code>docker attach CONTAINER</code> Attacher \u00e0 un conteneur <code>docker cp CONTAINER:PATH HOSTPATH</code> Copier les fichiers du conteneur <code>docker cp HOSTPATH CONTAINER:PATH</code> Copier les fichiers dans le conteneur <code>docker export CONTAINER</code> ExExporter le contenu du conteneur (archive tar) <code>docker exec CONTAINER</code> Ex\u00e9cuter une commande dans un conteneur <code>docker exec -it CONTAINER /bin/bash</code> Ouvrez un shell interactif dans un conteneur (il n'y a pas de bash dans certaines images, utilisez /bin/sh) <code>docker wait CONTAINER</code> Attendez que le conteneur se termine et renvoyez le code de sortie"},{"location":"wiki/docker/docker-cli/#images","title":"Images","text":"COMMAND DESCRIPTION <code>docker images</code> R\u00e9pertorier toutes les images locales <code>docker history IMAGE</code> Afficher l'historique des images <code>docker inspect IMAGE</code> SAfficher les informations (au format JSON) <code>docker tag IMAGE TAG</code> Marquer/Tagguer une image <code>docker commit CONTAINER IMAGE</code> Cr\u00e9er une image (\u00e0 partir d'un conteneur) <code>docker import URL</code> Cr\u00e9er une image (\u00e0 partir d'une archive tar) <code>docker rmi IMAGE</code> Supprimer des images <code>docker pull REPO:[TAG]</code> Extraire une image/un d\u00e9p\u00f4t d'un registre <code>docker push REPO:[TAG]</code> Pousser une image/d\u00e9p\u00f4t vers un registre <code>docker search TEXT</code> Rechercher une image sur le registre officiel <code>docker login</code> Se connecter \u00e0 un registre <code>docker logout</code> Se d\u00e9connecter d'un registre <code>docker save REPO:[TAG]</code> Exporter une image/un d\u00e9p\u00f4t sous forme d'archive tar <code>docker load</code> Charger des images \u00e0 partir d'une archive tar"},{"location":"wiki/docker/docker-cli/#volumes","title":"Volumes","text":"COMMAND DESCRIPTION <code>docker volume ls</code> Lister tous les volumes <code>docker volume create VOLUME</code> Cr\u00e9er un volume <code>docker volume inspect VOLUME</code> Afficher les informations (au format JSON) <code>docker volume rm VOLUME</code> D\u00e9truire un volume <code>docker volume ls --filter=\"dangling=true\"</code> R\u00e9pertorier tous les volumes en suspens (non r\u00e9f\u00e9renc\u00e9s par aucun conteneur) <code>docker volume prune</code> Supprimer tous les volumes (non r\u00e9f\u00e9renc\u00e9s par aucun conteneur)"},{"location":"wiki/docker/docker-cli/#sauvegarder-un-conteneur","title":"Sauvegarder un conteneur","text":"<p>Sauvegardez les donn\u00e9es Docker \u00e0 partir des volumes du conteneur et regroupez-les dans une archive tarball :</p> <ul> <li><code>docker run --rm --volumes-from CONTAINER -v $(pwd):/backup busybox tar cvfz /backup/backup.tar CONTAINERPATH</code></li> </ul> <p>Une sauvegarde automatis\u00e9e peut \u00e9galement \u00eatre effectu\u00e9e par ce playbook Ansible. La sortie est \u00e9galement un tar (compress\u00e9). Le playbook peut \u00e9galement g\u00e9rer la conservation des sauvegardes. Les anciennes sauvegardes seront donc automatiquement supprim\u00e9es.</p> <p>Pour cr\u00e9er et sauvegarder \u00e9galement la configuration du conteneur lui-m\u00eame, vous pouvez utiliser \u00ab docker-replay \u00bb pour cela. Si tu perds le conteneur entier, vous pouvez le recr\u00e9er avec l'exportation depuis <code>docker-replay</code>. Un didacticiel plus d\u00e9taill\u00e9 sur l'utilisation de docker-replay peut \u00eatre trouv\u00e9 ici.</p>"},{"location":"wiki/docker/docker-cli/#restaurer-le-conteneur-a-partir-dune-sauvegarde","title":"Restaurer le conteneur \u00e0 partir d'une sauvegarde","text":"<p>Restaurez le volume avec une archive tarball :</p> <ul> <li><code>docker run --rm --volumes-from CONTAINER -v $(pwd):/backup busybox sh -c \"cd CONTAINERPATH &amp;&amp; tar xvf /backup/backup.tar --strip 1\"</code></li> </ul>"},{"location":"wiki/git/","title":"Wiki - GIT","text":""},{"location":"wiki/git/#creer-un-nouveau-referentiel-en-ligne-de-commande","title":"Cr\u00e9er un nouveau r\u00e9f\u00e9rentiel en ligne de commande","text":"<pre><code>echo \"# test\" &gt;&gt; README.md\ngit init\ngit add README.md\ngit commit -m \"first commit\"\ngit branch -M main\ngit remote add origin https://github.com/allfab/XXXXX.git\ngit push -u origin main\n</code></pre>"},{"location":"wiki/git/#pousser-un-referentiel-existant-en-ligne-de-commande","title":"Pousser un r\u00e9f\u00e9rentiel existant en ligne de commande","text":"<pre><code>git remote add origin https://github.com/allfab/XXXXX.git\ngit branch -M main\ngit push -u origin main\n</code></pre>"},{"location":"wiki/git/#git-large-file-system-initialisation","title":"GIT Large File System initialisation","text":"<pre><code>git lfs install\ngit lfs track \"*.bin.zip\"\ngit add .gitattributes\n\ngit add docker-compose/stacks/igeo-stack/gdal/resources/hexagon/ECWJP2SDKSetup_5.5.0.2268.bin.zip\ngit commit -m \"ADD ECW/JP2 FILE support\"\ngit push origin main\n</code></pre>"},{"location":"wiki/linux/","title":"Wiki - Linux - Sommaire","text":"","tags":["Wiki","Linux"]},{"location":"wiki/linux/#sommaire","title":"Sommaire","text":"<ul> <li> <p> 01.G\u00e9n\u00e9ralit\u00e9s Syst\u00e8me</p> <ul> <li>LVM sous Linux</li> </ul> <p> En savoir plus</p> </li> <li> <p> 02.Commandes de base</p> <ul> <li>LSBLK : Lister les disques et les partitions du syst\u00e8me</li> </ul> <p> En savoir plus</p> </li> <li> <p> 03.Services &amp; Serveurs</p> <ul> <li>SSH</li> </ul> <p> En savoir plus</p> </li> </ul>","tags":["Wiki","Linux"]},{"location":"wiki/linux/basic-commands/","title":"WIKI - Linux -  Commandes de base","text":"","tags":["Wiki","Linux","Commandes de base"]},{"location":"wiki/linux/basic-commands/#sommaire","title":"Sommaire","text":"<ul> <li> <p> 02. Commandes de base</p> <ul> <li>LSBLK : Lister les disques et les partitions du syst\u00e8me</li> </ul> <p> En savoir plus</p> </li> </ul>","tags":["Wiki","Linux","Commandes de base"]},{"location":"wiki/linux/services-servers/","title":"WIKI - Linux - Services &amp; Serveurs","text":"","tags":["Wiki","Linux","Services & Serveurs"]},{"location":"wiki/linux/services-servers/#sommaire","title":"Sommaire","text":"<ul> <li> <p> 03.Services &amp; Serveurs</p> <ul> <li>SSH</li> </ul> <p> En savoir plus</p> </li> </ul>","tags":["Wiki","Linux","Services & Serveurs"]},{"location":"wiki/linux/system/","title":"WIKI - Linux - G\u00e9n\u00e9ralit\u00e9s Syst\u00e8me","text":"","tags":["Wiki","Linux","G\u00e9n\u00e9ralit\u00e9s Syst\u00e8me"]},{"location":"wiki/linux/system/#sommaire","title":"Sommaire","text":"<ul> <li> <p> 01.G\u00e9n\u00e9ralit\u00e9s Syst\u00e8me</p> <ul> <li>LVM sous Linux</li> </ul> <p> En savoir plus</p> </li> </ul>","tags":["Wiki","Linux","G\u00e9n\u00e9ralit\u00e9s Syst\u00e8me"]},{"location":"wiki/linux/basics/lsblk/","title":"WIKI - Linux - Commandes de base","text":"","tags":["Wiki","Linux","LSBLK"]},{"location":"wiki/linux/basics/lsblk/#lister-les-disques-et-les-partitions-du-systeme-avec-lutilitaire-lsblk","title":"Lister les disques et les partitions du syst\u00e8me avec l'utilitaire LSBLK","text":"","tags":["Wiki","Linux","LSBLK"]},{"location":"wiki/linux/basics/lsblk/#lsblk","title":"LSBLK","text":"","tags":["Wiki","Linux","LSBLK"]},{"location":"wiki/linux/basics/lsblk/#installation-sous-debian","title":"Installation sous Debian","text":"<pre><code>apt-get install util-linux\n</code></pre>","tags":["Wiki","Linux","LSBLK"]},{"location":"wiki/linux/basics/lsblk/#usage","title":"Usage","text":"<p>La commande\u00a0<code>lsblk</code>\u00a0permet d'obtenir la liste et les caract\u00e9ristiques des disques et de leurs partitions. La commande ne n\u00e9cessite pas les droits administrateurs pour \u00eatre ex\u00e9cut\u00e9e.  </p> <p>Afficher des renseignements sur les syst\u00e8mes de fichiers : <pre><code>lsblk -f\n</code></pre></p> <pre><code>lsblk -o NAME,TYPE,PARTTYPE,MOUNTPOINT,FSTYPE,FSSIZE,SIZE,FSAVAIL,FSUSE%,ALIGNMENT,UUID,MODEL,SERIAL,PHY-SEC\n</code></pre> <pre><code>lsblk -o NAME,LABEL,TYPE,MOUNTPOINT,FSTYPE,FSSIZE,SIZE,FSAVAIL,FSUSE%,ALIGNMENT,UUID,MODEL,SERIAL,PHY-SEC\n</code></pre> <p>Retour de la commande : <pre><code>NAME \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0TYPE PARTTYPENAME \u00a0 \u00a0 MOUNTPOINTS \u00a0 \u00a0 FSTYPE \u00a0 \u00a0 \u00a0FSVER \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 SIZE FSAVAIL FSUSE% ALIGNMENT UUID \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 MODEL \u00a0 \u00a0 \u00a0 \u00a0 SERIAL \u00a0 \u00a0 \u00a0PHY-SEC\n\nsda \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 disk \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 22G \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0QEMU HARDDISK drive-scsi0 \u00a0 \u00a0 512\n\n\u251c\u2500sda1 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0part Linux filesystem /boot \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ext4 \u00a0 \u00a0 \u00a0 \u00a01.0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 953M \u00a0797,1M \u00a0 \u00a0 6% \u00a0 \u00a0 \u00a0 \u00a0 0 d26adfa3-c7a2-4f78-8730-305a6a6ef842 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 512\n\n\u2514\u2500sda2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0part Linux LVM \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0LVM2_member LVM2 001 \u00a0 \u00a0 \u00a0 \u00a0 21,1G \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00 7VFATj-KLBq-UU44-1QlS-Uz26-T62h-TJZohf \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 512\n\n\u00a0 \u251c\u2500rootvg-rootlv lvm \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ext4 \u00a0 \u00a0 \u00a0 \u00a01.0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a019,2G \u00a0 \u00a09,8G \u00a0 \u00a043% \u00a0 \u00a0 \u00a0 \u00a0 0 805d9569-909c-439f-b596-0f1513144761 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 512\n\n\u00a0 \u2514\u2500rootvg-swaplv lvm \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [SWAP] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0swap \u00a0 \u00a0 \u00a0 \u00a01 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 1,9G \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00 18856f92-824a-4d4b-bcc4-472f7c96cddd \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 512\n\nsdb \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 disk \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0100G \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0QEMU HARDDISK drive-scsi1 \u00a0 \u00a0 512\n\n\u2514\u2500sdb1 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0part Linux filesystem /var/lib/docker btrfs \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 100G \u00a0 86,8G \u00a0 \u00a012% \u00a0 \u00a0 \u00a0 \u00a0 0 603cef1a-f969-4374-b45b-0fe4d460149e \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 512\n\nsr0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 rom \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 iso9660 \u00a0 \u00a0 Joliet Extension \u00a0628M \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00 2023-10-07-10-32-09-00 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 QEMU DVD-ROM \u00a0QM00003 \u00a0 \u00a0 \u00a0 \u00a02048\n</code></pre></p>","tags":["Wiki","Linux","LSBLK"]},{"location":"wiki/linux/services_servers/ssh/","title":"WIKI - Linux - Services","text":"","tags":["Wiki","Linux","SSH"]},{"location":"wiki/linux/services_servers/ssh/#configuration-ssh","title":"Configuration - SSH","text":"","tags":["Wiki","Linux","SSH"]},{"location":"wiki/linux/services_servers/ssh/#generation-dune-nouvelle-cle-ssh","title":"G\u00e9n\u00e9ration d\u2019une nouvelle cl\u00e9 SSH","text":"<p>Vous pouvez g\u00e9n\u00e9rer une nouvelle cl\u00e9 SSH sur votre ordinateur local. Apr\u00e8s avoir g\u00e9n\u00e9r\u00e9 la cl\u00e9, vous pouvez ajouter la cl\u00e9 publique \u00e0 votre serveur.</p> <p>G\u00e9n\u00e9ration via l'outil ssh-keygen</p> <p><code>ssh-keygen</code> fourni un prompt pour vous aider</p> <p>ATTENTION</p> <p>Ajouter une passphrase sinon une clef ssh est plus dangereuse qu'un password</p> <p>Usage basique : <pre><code>ssh-keygen -t ecdsa -b 521\n</code></pre></p> <ul> <li><code>-t</code> : Type de clef / Algorithme utilis\u00e9 (rsa, dsa, ecdsa),</li> <li><code>-b</code> : Longeur de clef (d\u00e9pend de l'algo: ici ecdsa 521).</li> </ul> <p>En sp\u00e9cifiant la localisation de sortie : <pre><code>ssh-keygen -t ecdsa -b 521 -f /home/&lt;user&gt;/.ssh/maclefprivee\n</code></pre></p> <ul> <li><code>-f</code> : localisation de sortie.</li> </ul>","tags":["Wiki","Linux","SSH"]},{"location":"wiki/linux/services_servers/ssh/#ajout-de-celle-ci-a-lhote-distant-via-ssh-agent","title":"Ajout de celle-ci \u00e0 l'h\u00f4te distant via ssh-agent","text":"<p>Ajout de la cl\u00e9 publique sur le host distant : <pre><code>vim /home/user/.ssh/authorized_keys\n</code></pre></p> <p>Via ssh-agent : <pre><code>ssh-copy-id -i /home/&lt;user&gt;/.ssh/maclefprivee user@monhost\n</code></pre></p> <p>Restreindre \u00e0 une adresse IP : <pre><code>from=\"10.0.0.?,*.example.com\",no-X11-forwarding ssh-rsa AB3Nz...EN8w== user@monhost\n</code></pre></p> <p>Utilisation de la cl\u00e9 : <pre><code>ssh -i /localisation/key/privee user@monhost\n</code></pre></p> <p>Configuration sur l'h\u00f4te h\u00e9bergeant la cl\u00e9 priv\u00e9e : <pre><code>touch ~/.ssh/config\nchmod 600 ~/.ssh/config\ncat ~/.ssh/config\n\nHost * !monhost*\n    User monuser\n    Port 22\n    IdentityFile /home/user/.ssh/maclefprivee\n    LogLevel INFO\n    Compression yes\n    ForwardAgent yes\n    ForwardX11 yes\n</code></pre></p> <p>Astuce pour bypasser la conf : <pre><code>ssh -F /dev/null user@monhosts\n</code></pre></p>","tags":["Wiki","Linux","SSH"]},{"location":"wiki/linux/services_servers/ssh/#supprimer-la-cle-de-known_hosts","title":"Supprimer la cl\u00e9 de known_hosts","text":"<pre><code>ssh-keygen -R &lt;hostname&gt;\n</code></pre>","tags":["Wiki","Linux","SSH"]},{"location":"wiki/linux/system/lvm/","title":"LVM sous Linux","text":"<p>R\u00e9f\u00e9rence : https://www.linuxtricks.fr/wiki/lvm-sous-linux-volumes-logiques</p>","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#cas-pratique-01","title":"Cas pratique #01","text":"","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#creation-et-montage-dun-volume-logigue-avec-point-de-montage-sous-home","title":"Cr\u00e9ation et montage d'un volume logigue avec point de montage sous <code>/home</code>","text":"<p>Liste et  caract\u00e9ristiques des disques avant configuration :</p> <pre><code>fdisk -l\n</code></pre> <pre><code>Disque /dev/sdb\u00a0: 160 GiB, 171798691840\u00a0octets, 335544320\u00a0secteurs\nMod\u00e8le de disque\u00a0: QEMU HARDDISK\nUnit\u00e9s\u00a0: secteur de 1 \u00d7 512 = 512\u00a0octets\nTaille de secteur (logique / physique)\u00a0: 512\u00a0octets / 512\u00a0octets\ntaille d E/S (minimale / optimale)\u00a0: 512\u00a0octets / 512\u00a0octets\n\n\nDisque /dev/sdc\u00a0: 32 GiB, 34359738368\u00a0octets, 67108864\u00a0secteurs\nMod\u00e8le de disque\u00a0: QEMU HARDDISK\nUnit\u00e9s\u00a0: secteur de 1 \u00d7 512 = 512\u00a0octets\nTaille de secteur (logique / physique)\u00a0: 512\u00a0octets / 512\u00a0octets\ntaille d E/S (minimale / optimale)\u00a0: 512\u00a0octets / 512\u00a0octets\n\n\nDisque /dev/sda\u00a0: 25 GiB, 26843545600\u00a0octets, 52428800\u00a0secteurs\nMod\u00e8le de disque\u00a0: QEMU HARDDISK\nUnit\u00e9s\u00a0: secteur de 1 \u00d7 512 = 512\u00a0octets\nTaille de secteur (logique / physique)\u00a0: 512\u00a0octets / 512\u00a0octets\ntaille d E/S (minimale / optimale)\u00a0: 512\u00a0octets / 512\u00a0octets\nType d \u00e9tiquette de disque\u00a0: dos\nIdentifiant de disque\u00a0: 0xcd15c49b\n\nP\u00e9riph\u00e9rique Amor\u00e7age   D\u00e9but      Fin Secteurs Taille Id Type\n/dev/sda1    *           2048   999423   997376   487M 83 Linux\n/dev/sda2             1001470 52426751 51425282  24,5G  5 \u00c9tendue\n/dev/sda5             1001472 52426751 51425280  24,5G 8e LVM Linux\n\n\nDisque /dev/mapper/SRVIGEOBD25--vg-root\u00a0: 23,54 GiB, 25274875904\u00a0octets, 49364992\u00a0secteurs\nUnit\u00e9s\u00a0: secteur de 1 \u00d7 512 = 512\u00a0octets\nTaille de secteur (logique / physique)\u00a0: 512\u00a0octets / 512\u00a0octets\ntaille d E/S (minimale / optimale)\u00a0: 512\u00a0octets / 512\u00a0octets\n\n\nDisque /dev/mapper/SRVIGEOBD25--vg-swap_1\u00a0: 976 MiB, 1023410176\u00a0octets, 1998848\u00a0secteurs\nUnit\u00e9s\u00a0: secteur de 1 \u00d7 512 = 512\u00a0octets\nTaille de secteur (logique / physique)\u00a0: 512\u00a0octets / 512\u00a0octets\ntaille d E/S (minimale / optimale)\u00a0: 512\u00a0octets / 512\u00a0octets\n</code></pre>","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#schema-de-partitionnement","title":"Sch\u00e9ma de partitionnement","text":"Disque Taille PV VG LV LV Path Syst\u00e8me de fichier Montage /dev/sda 23,54GB /dev/sda5 SRVIGEOBD25-vg root /dev/SRVIGEOBD25-vg/root ext4 / /dev/sda 976MB /dev/sda5 SRVIGEOBD25-vg swap_1 /dev/SRVIGEOBD25-vg/swap_1 swap swap /dev/sdc 32GB /dev/sdc1 SRVIGEOBD25-home-vg home /dev/SRVIGEOBD25-home-vg/home-lv ext4 /home","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#creation-du-volume-logique-home-sur-devsdc","title":"Cr\u00e9ation du volume logique /home sur /dev/sdc","text":"<p>Pr\u00e9requis LVM - Partitionnement du disque - en cr\u00e9ant la partition et en d\u00e9finissant le type sur LVM Linux : <pre><code>cfdisk /dev/sdc\n</code></pre></p> <p>V\u00e9rification de l'op\u00e9ration : <pre><code>fdisk -l /dev/sdc\n</code></pre></p> <pre><code>Disque /dev/sdc\u00a0: 32 GiB, 34359738368\u00a0octets, 67108864\u00a0secteurs\nMod\u00e8le de disque\u00a0: QEMU HARDDISK\nUnit\u00e9s\u00a0: secteur de 1 \u00d7 512 = 512\u00a0octets\nTaille de secteur (logique / physique)\u00a0: 512\u00a0octets / 512\u00a0octets\ntaille d E/S (minimale / optimale)\u00a0: 512\u00a0octets / 512\u00a0octets\nType d \u00e9tiquette de disque\u00a0: gpt\nIdentifiant de disque\u00a0: 319DF41A-C31C-124A-B115-E44284196AB7\n\nP\u00e9riph\u00e9rique D\u00e9but      Fin Secteurs Taille Type\n/dev/sdc1     2048 67106815 67104768    32G LVM Linux\n</code></pre>","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#creation-du-volume-physique-pv","title":"Cr\u00e9ation du volume physique PV","text":"<pre><code>pvcreate /dev/sdc1\nPhysical volume \"/dev/sdc1\" successfully created.\n</code></pre> <p>Afficher les infos du PV cr\u00e9\u00e9 : <pre><code>pvdisplay /dev/sdc\n</code></pre></p> <pre><code>--- Physical volume ---\n  PV Name               /dev/sda5\n  VG Name               SRVIGEOBD25-vg\n  PV Size               24,52 GiB / not usable 2,00 MiB\n  Allocatable           yes\n  PE Size               4,00 MiB\n  Total PE              6277\n  Free PE               7\n  Allocated PE          6270\n  PV UUID               NYyRyD-FZFJ-UBqS-fG94-7ZoG-CCMc-CGBRxY\n\n  \"/dev/sdc1\" is a new physical volume of \"&lt;32,00 GiB\"\n  --- NEW Physical volume ---\n  PV Name               /dev/sdc1\n  VG Name\n  PV Size               &lt;32,00 GiB\n  Allocatable           NO\n  PE Size               0\n  Total PE              0\n  Free PE               0\n  Allocated PE          0\n  PV UUID               yvLOCy-Xenj-2Tqt-A2HI-MKfL-x0wG-XfpY6T\n</code></pre>","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#creation-du-groupe-de-volume-vg","title":"Cr\u00e9ation du groupe de volume VG","text":"<pre><code>vgcreate SRVIGEOBD25-home-vg /dev/sdc1\nVolume group \"SRVIGEOBD25-home-vg\" successfully created\n</code></pre> <p>Afficher les infos du VG cr\u00e9\u00e9 : <pre><code>vgdisplay\n</code></pre></p> <pre><code> --- Volume group ---\n  VG Name               SRVIGEOBD25-home-vg\n  System ID\n  Format                lvm2\n  Metadata Areas        1\n  Metadata Sequence No  1\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                0\n  Open LV               0\n  Max PV                0\n  Cur PV                1\n  Act PV                1\n  VG Size               &lt;32,00 GiB\n  PE Size               4,00 MiB\n  Total PE              8191\n  Alloc PE / Size       0 / 0\n  Free  PE / Size       8191 / &lt;32,00 GiB\n  VG UUID               Ynkint-gq4S-mQ87-0hRs-StYU-33Y2-xjonMM\n\n  --- Volume group ---\n  VG Name               SRVIGEOBD25-vg\n  System ID\n  Format                lvm2\n  Metadata Areas        1\n  Metadata Sequence No  3\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                2\n  Open LV               2\n  Max PV                0\n  Cur PV                1\n  Act PV                1\n  VG Size               &lt;24,52 GiB\n  PE Size               4,00 MiB\n  Total PE              6277\n  Alloc PE / Size       6270 / 24,49 GiB\n  Free  PE / Size       7 / 28,00 MiB\n  VG UUID               mQJ0KH-La6N-Qd7t-g2Gv-Bj5I-vWuj-xMdWyV\n</code></pre>","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#creation-du-volume-logique-lv","title":"Cr\u00e9ation du volume logique LV","text":"<pre><code>lvcreate -n home-lv -l 100%FREE SRVIGEOBD25-home-vg\nLogical volume \"home-lv\" created.\n</code></pre> <pre><code>lvdisplay\n--- Logical volume ---\n  LV Path                /dev/SRVIGEOBD25-home-vg/home-lv\n  LV Name                home-lv\n  VG Name                SRVIGEOBD25-home-vg\n  LV UUID                gIenFG-3ol1-W0rb-dbWN-vBfr-mAvc-uH92FC\n  LV Write Access        read/write\n  LV Creation host, time SRVIGEOBD25, 2024-11-18 17:07:08 +0100\n  LV Status              available\n  # open                 0\n  LV Size                &lt;32,00 GiB\n  Current LE             8191\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           254:2\n\n  --- Logical volume ---\n  LV Path                /dev/SRVIGEOBD25-vg/root\n  LV Name                root\n  VG Name                SRVIGEOBD25-vg\n  LV UUID                gk71ZU-0CYu-C7T0-iLfS-c3vG-NxdZ-03P3mF\n  LV Write Access        read/write\n  LV Creation host, time SRVIGEOBD25, 2024-11-15 10:23:50 +0100\n  LV Status              available\n  # open                 1\n  LV Size                &lt;23,54 GiB\n  Current LE             6026\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           254:0\n\n  --- Logical volume ---\n  LV Path                /dev/SRVIGEOBD25-vg/swap_1\n  LV Name                swap_1\n  VG Name                SRVIGEOBD25-vg\n  LV UUID                xp7Z3A-HOtA-bncI-bFSJ-XMa2-FpQX-ALsj5T\n  LV Write Access        read/write\n  LV Creation host, time SRVIGEOBD25, 2024-11-15 10:23:51 +0100\n  LV Status              available\n  # open                 2\n  LV Size                976,00 MiB\n  Current LE             244\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           254:1\n</code></pre>","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#ajout-du-systeme-de-fichier-sur-le-volume-logique-lv","title":"Ajout du syst\u00e8me de fichier sur le volume logique LV","text":"<pre><code>mkfs.ext4 -L home /dev/SRVIGEOBD25-home-vg/home-lv\n</code></pre> <pre><code>mke2fs 1.47.0 (5-Feb-2023)\nDiscarding device blocks: done\nCreating filesystem with 8387584 4k blocks and 2097152 inodes\nFilesystem UUID: 529c9ce8-cc88-44cf-986a-c1fbeacc6c86\nSuperblock backups stored on blocks:\n        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,\n        4096000, 7962624\n\nAllocating group tables: done\nWriting inode tables: done\nCreating journal (32768 blocks): done\nWriting superblocks and filesystem accounting information: done\n</code></pre>","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#montage-du-systeme-de-fichier","title":"Montage du syst\u00e8me de fichier","text":"<p>Le dossier <code>/home</code> n'est pas vide. Il contient le r\u00e9pertoire de l'utilisateur <code>adminsig</code>. On va le d\u00e9placer temporairement dans le dossier <code>tmp</code> avant de monter le volume logique sur <code>/home</code> : <pre><code>mv /home/adminsig /tmp\n</code></pre></p> <pre><code>mkdir -p /home\nmount /dev/SRVIGEOBD25-home-vg/home-lv /home\n</code></pre> <p>Ou de cette fa\u00e7on : <pre><code>mount /dev/mapper/SRVIGEOBD25--home--vg--home--lv /home\n</code></pre></p> <pre><code>duf\n</code></pre> <pre><code>Retour\n</code></pre> <p>On contr\u00f4le avec la commande <code>mount</code> ou <code>df</code> que le syst\u00e8me de fichier (FS) est bien mont\u00e9 : <pre><code>mount | grep home\n</code></pre></p> <pre><code>df | grep home\n</code></pre>","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#fstab-pour-rendre-le-montage-permanent-sur-le-systeme","title":"FSTAB pour rendre le montage permanent sur le syst\u00e8me","text":"<pre><code>vi /etc/fstab\n\n# AJOUTER LA LIGNE\n/dev/mapper/SRVIGEOBD25-home-vg-home-lv /home ext4 defaults 0 0\n</code></pre> <pre><code>systemctl daemon-reload\n</code></pre> <p>V\u00e9rification de la validit\u00e9 du fichier <code>/etc/fstab</code> : <pre><code>findmnt --verify --verbose\n\n/\n   [ ] la cible existe\n   [ ] options FS\u00a0: errors=remount-ro\n   [ ] la source /dev/mapper/SRVIGEOBD25--vg-root existe\n   [ ] le type du syst\u00e8me de fichier est ext4\n/home\n   [ ] la cible existe\n   [ ] la source /dev/mapper/SRVIGEOBD25--home--vg-home--lv existe\n   [ ] le type du syst\u00e8me de fichier est ext4\n/boot\n   [ ] la cible existe\n   [ ] UUID=1e2f9456-e99c-4d2a-a8e9-4d86145ba0f9 traduit en /dev/sda1\n   [ ] la source /dev/sda1 existe\n   [ ] le type du syst\u00e8me de fichier est ext2\nnone\n   [ ] la source /dev/mapper/SRVIGEOBD25--vg-swap_1 existe\n   [ ] le type du syst\u00e8me de fichier est swap\n/media/cdrom0\n   [ ] la cible existe\n   [ ] options en espace utilisateur\u00a0: user,noauto\n   [ ] la source /dev/sr0 existe\n   [W] impossible de d\u00e9tecter le type de syst\u00e8me de fichiers du disque (Aucun m\u00e9dium trouv\u00e9)\n\n0 erreur d'analyse, 0 erreur, 1 alerte\n</code></pre></p> <p>On termine la proc\u00e9dure en repla\u00e7ant le dossier <code>adminsig</code> dans le r\u00e9pertoire <code>/home</code> qui est maintenant monter sur le volume logique fraichement configur\u00e9 : <pre><code>mv /tmp/adminsig /home\n</code></pre></p>","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#cas-pratique-02","title":"Cas pratique #02","text":"","tags":["Wiki","Linux","LVM"]},{"location":"wiki/linux/system/lvm/#creation-et-montage-dun-volume-logigue-avec-point-de-montage-sous-var","title":"Cr\u00e9ation et montage d'un volume logigue avec point de montage sous <code>/var</code>","text":"","tags":["Wiki","Linux","LVM"]}]}